{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example of a SLP and MLP for Classification and Regression\n",
    "\n",
    "This is a basic example of a Single and Multilayer Perceptron for Classification and Regression based on keras.\n",
    "It also uses sklearn for auxiliar functions.\n",
    "\n",
    "The general scheme is as follows:\n",
    "- Set the values of the global variables\n",
    "- Load data\n",
    "- Preprocess data\n",
    "- Split data into training and test\n",
    "- Create the architecture\n",
    "- Select the elements previous to the training phase: loss function, training algorithm, ...\n",
    "- Train the system with the training data\n",
    "- Test the model\n",
    "\n",
    "Keras documentation: https://keras.io/api\n",
    "\n",
    "Sklearn documentation: https://scikit-learn.org/stable/user_guide.html\n",
    "\n",
    "**This script has been tested with the following package versions:**\n",
    "- pandas 1.3.3\n",
    "- sklearn 0.24.0\n",
    "- keras 2.2.4 + tensorflow 1.14.0 / keras 2.6.0 + tensorflow 2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataFunctions                ### Functions for data management\n",
    "import numpy                        ### Library for numerical computations\n",
    "import keras, tensorflow, sklearn   ### Libraries for constructing and training the models\n",
    "import matplotlib.pyplot as plt     ### Library for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we set the values of several global variables\n",
    "MULTILAYER_PERCEPTRON = False  ### If False, it is a Single-layer Perceptron\n",
    "CLASSIFICATION        = True   ### If False, it is a REGRESSION problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we read inputs and labels\n",
    "inputsFileName   = 'Data/ionosphere.inputs'\n",
    "labelsFileName = 'Data/ionosphere.labels'\n",
    "#inputsFileName   = 'Data/hepatitis.inputs'\n",
    "#labelsFileName = 'Data/hepatitis.labels'\n",
    "#inputsFileName   = 'Data/sonar.inputs'\n",
    "#labelsFileName = 'Data/sonar.labels'\n",
    "x, y = DataFunctions.loadDatasetsFromFiles (inputsFileName, labelsFileName)\n",
    "y    = y.ravel()   ### sklearn prefers shapes (N,) than (N,1)\n",
    "\n",
    "nExamples = x.shape[0]\n",
    "nFeatures = x.shape[1]\n",
    "if CLASSIFICATION:\n",
    "    nClasses  = len(numpy.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labels to a 1-of-C (one-hot) scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### For neural networks, it is easier to output yes/no than (for example) an integer with the predicted class\n",
    "if CLASSIFICATION:\n",
    "    y1C  = DataFunctions.convertLabels_1ofC_Scheme (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print Some Information about inputs and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Type, dimensions, number of examples in every class, first rows, ...\n",
    "print(\"Type of variable x: %s\" % type(x))\n",
    "print(\"Type of variable y: %s\" % type(y))\n",
    "print(\"Dimensions of variable   x: %3d %3d  \" % x.shape,   end=\"\"); print(\"  shape:\",x.shape)\n",
    "print(\"Dimensions of variable   y: %3d      \" % y.shape,   end=\"\"); print(\"  shape:\",y.shape)\n",
    "if CLASSIFICATION:\n",
    "    print(\"Dimensions of variable y1C: %3d %3d  \" % y1C.shape, end=\"\"); print(\"  shape:\",y1C.shape)\n",
    "    print(\"Number of examples in every class:\")\n",
    "    for i in numpy.unique(y):\n",
    "        print (\"  class %d: %d\" % (i,sum(y==i)))\n",
    "print(\"First 3 rows of x:\"); print(x[0:3,])\n",
    "print(\"First 3 rows of y:\"); print(y[0:3])\n",
    "if CLASSIFICATION:\n",
    "    print(\"First 3 rows of y1C:\"); print(y1C[0:3,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we scale the inputs\n",
    "x, Scaler = DataFunctions.scaleDataMean0Dev1Scaler (x)\n",
    "#x, Scaler = DataFunctions.scaleDataMinMaxScaler (x, FeatureRange=(-1,+1))\n",
    "print(\"First 3 rows of x:\"); print(x[0:3,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and labels into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into training (to construct the model) and test (to estimate the generalization)\n",
    "from sklearn import model_selection\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  model_selection.train_test_split (x, y, train_size=0.70, shuffle=True, stratify=y)\n",
    "if CLASSIFICATION:\n",
    "    y1C_train = DataFunctions.convertLabels_1ofC_Scheme (y_train)\n",
    "    y1C_test  = DataFunctions.convertLabels_1ofC_Scheme (y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Print some information about training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Same as above\n",
    "print(\"Dimensions of variable   x_train: %3d %3d \" % x_train.shape, end=\"\");   print(\"  shape:\",x_train.shape)\n",
    "print(\"Dimensions of variable   y_train: %3d     \" % y_train.shape, end=\"\");   print(\"  shape:\",y_train.shape)\n",
    "if CLASSIFICATION:\n",
    "    print(\"Dimensions of variable y1C_train: %3d %3d \" % y1C_train.shape, end=\"\"); print(\"  shape:\",y1C_train.shape)\n",
    "    print(\"Number of examples in every class in x_train:\")\n",
    "    for i in numpy.unique(y_train):\n",
    "        print (\"  class %d: %3d\" % (i,sum(y_train==i)))\n",
    "print(\"Dimensions of variable   x_test: %3d %3d \" % x_test.shape, end=\"\");   print(\"  shape:\",x_test.shape)\n",
    "print(\"Dimensions of variable   y_test: %3d     \" % y_test.shape, end=\"\");   print(\"  shape:\",y_test.shape)\n",
    "if CLASSIFICATION:\n",
    "    print(\"Dimensions of variable y1C_test: %3d %3d \" % y1C_test.shape, end=\"\"); print(\"  shape:\",y1C_test.shape)\n",
    "    print(\"Number of examples in every class in x_test:\")\n",
    "    for i in numpy.unique(y_test):\n",
    "        print (\"  class %d: %3d\" % (i,sum(y_test==i)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the architecture (Type of Problem + Model Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### https://keras.io/api/models/sequential/#sequential-class\n",
    "###\n",
    "\n",
    "### First we indicate that it is a sequential model\n",
    "myNetwork = keras.Sequential()\n",
    "\n",
    "if CLASSIFICATION:\n",
    "    nOutput           = nClasses\n",
    "    fActivationOutput = 'softmax'\n",
    "else:\n",
    "    nOutput           = 1\n",
    "    fActivationOutput = 'linear'\n",
    "\n",
    "### We need to indicate the input dimension in the first layer\n",
    "inputDimension = nFeatures\n",
    "\n",
    "if MULTILAYER_PERCEPTRON:\n",
    "\n",
    "    ### Now we add the hidden layers\n",
    "    nHidden1     = 100\n",
    "    fActivation1 = 'tanh'\n",
    "    myNetwork.add ( keras.layers.Dense (nHidden1, activation=fActivation1, input_dim=inputDimension) )\n",
    "    #myNetwork.add ( keras.layers.Dense (nHidden1, activation=fActivation1, kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01), input_dim=nFeatures) )\n",
    "    nHidden2     = 50\n",
    "    fActivation2 = 'tanh'\n",
    "    myNetwork.add ( keras.layers.Dense (nHidden2, activation=fActivation2) )\n",
    "    #myNetwork.add ( keras.layers.Dense (nHidden2, activation=fActivation2, kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01)) )\n",
    "\n",
    "    ### And finally we add the output layer\n",
    "    myNetwork.add ( keras.layers.Dense (nOutput, activation=fActivationOutput) )\n",
    "\n",
    "else:\n",
    "\n",
    "    ### We only have an output layer\n",
    "    myNetwork.add ( keras.layers.Dense (nOutput, activation=fActivationOutput, input_dim=inputDimension) )\n",
    "\n",
    "### Print statistics\n",
    "print(myNetwork.summary())\n",
    "\n",
    "### Now we create a keras model\n",
    "myInput = keras.layers.Input (shape=(nFeatures,))\n",
    "myModel = keras.models.Model (inputs=myInput, outputs=myNetwork(myInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a loss function (Type of Problem + Cost Function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Usual loss functions: 'categorical_crossentropy' 'binary_crossentropy' 'mean_squared_error', etc\n",
    "if CLASSIFICATION:\n",
    "    lossFunction = ['categorical_crossentropy']  # For one-hot labels, use categorical_crossentropy\n",
    "else:\n",
    "    lossFunction = ['mean_squared_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select a training algorithm and its parameters (Optimization Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Every training algorithm will have its own parameters\n",
    "LearningRate = 0.01\n",
    "Momentum     = 0.8\n",
    "#print(keras.__version__)\n",
    "if keras.__version__ == \"2.2.4\":\n",
    "    optimizers = keras.optimizers\n",
    "else:\n",
    "    optimizers = tensorflow.keras.optimizers\n",
    "trainAlgorithm = optimizers.SGD (lr=LearningRate, momentum=Momentum)  # There are more parameters\n",
    "#\n",
    "#LearningRate = 0.01\n",
    "#trainAlgorithm = optimizers.RMSprop (lr=LearningRate)                 # There are more parameters\n",
    "#\n",
    "#LearningRate = 0.01\n",
    "#trainAlgorithm = optimizers.Adam (lr=LearningRate)                    # There are more parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the metrics we want to monitorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Keras allows to monitorize several metrics along training\n",
    "if CLASSIFICATION:\n",
    "    showMetrics = ['categorical_accuracy', 'mean_squared_error']  # For one-hot labels, use categorical_accuracy\n",
    "else:\n",
    "    showMetrics = ['mean_squared_error']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile the model with all the elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This is the standard way to work in keras\n",
    "myModel.compile (loss=lossFunction, optimizer=trainAlgorithm, metrics=showMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### This method has many parameters:\n",
    "###   https://keras.io/api/models/model_training_apis/#fit-method\n",
    "###\n",
    "\n",
    "batchSize = 20\n",
    "nEpochs   = 200\n",
    "if CLASSIFICATION:\n",
    "    validationData = (x_test,y1C_test)  ### We could also use the validation_split parameter\n",
    "    fitData = myModel.fit \\\n",
    "      (x_train, y1C_train, validation_data=validationData, batch_size=batchSize, epochs=nEpochs)\n",
    "else:\n",
    "    validationData = (x_test,y_test)    ### We could also use the validation_split parameter\n",
    "    fitData = myModel.fit \\\n",
    "      (x_train, y_train,   validation_data=validationData, batch_size=batchSize, epochs=nEpochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model in the training and test data at the end of the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION:\n",
    "    scoresTrain = myModel.evaluate (x_train,y1C_train)\n",
    "    scoresTest  = myModel.evaluate (x_test,y1C_test)\n",
    "    print(\"Loss function and Accuracy in the training set: %.8f  %7.3f%%\" % (scoresTrain[0], 100*scoresTrain[1])) \n",
    "    print(\"Loss function and Accuracy in the test set:     %.8f  %7.3f%%\" % (scoresTest[0],  100*scoresTest[1]))\n",
    "else:\n",
    "    scoresTrain = myModel.evaluate (x_train,y_train)\n",
    "    scoresTest  = myModel.evaluate (x_test,y_test)\n",
    "    print(\"Loss function and Squared Error in the training set: %.8f  %.8f\" % (scoresTrain[0], scoresTrain[1])) \n",
    "    print(\"Loss function and Squared Error in the test set:     %.8f  %.8f\" % (scoresTest[0],  scoresTest[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(fitData)); print(fitData); print(\"---\")\n",
    "print(dir(fitData)); print(\"---\")\n",
    "print(type(fitData.history)); print(fitData.history.keys());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossTrain = fitData.history[\"loss\"]\n",
    "lossValid = fitData.history[\"val_loss\"]\n",
    "\n",
    "epochsPlot = range(1,len(lossTrain)+1)\n",
    "\n",
    "plt.plot(epochsPlot,lossTrain,label='Training Loss')\n",
    "plt.plot(epochsPlot,lossValid,label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CLASSIFICATION:\n",
    "    accuracyTrain = fitData.history[\"categorical_accuracy\"]\n",
    "    accuracyValid = fitData.history[\"val_categorical_accuracy\"]\n",
    "\n",
    "    epochsPlot = range(1,len(accuracyTrain)+1)\n",
    "\n",
    "    plt.plot(epochsPlot,accuracyTrain,label='Training Accuracy')\n",
    "    plt.plot(epochsPlot,accuracyValid,label='Validation Accuracy')\n",
    "\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
