{"cells":[{"cell_type":"markdown","metadata":{"id":"Sk0eYw8ojrFq"},"source":["# Laboratory #4_2 : Image Classification using Bag of Visual Words\n","\n","At the end of this laboratory, you would get familiarized with\n","\n","*   Creating Bag of Visual Words\n","    *   Feature Extraction\n","    *   Codebook construction\n","    *   Classification\n","*   Using pre-trained deep networks for feature extraction\n","\n","**Remember this is a graded exercise.**\n","\n","*   For every plot, make sure you provide appropriate titles, axis labels, legends, wherever applicable.\n","*   Create reusable functions where ever possible, so that the code could be reused at different places.\n","*   Mount your drive to access the images.\n","*   Add sufficient comments and explanations wherever necessary.\n","\n","---"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYHw1lSBldl-"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aD5-E8PuaQ5P"},"outputs":[],"source":["# Loading necessary libraries (Feel free to add new libraries if you need for any computation)\n","\n","import os\n","import numpy as np\n","\n","from skimage.feature import ORB \n","from skimage.color import rgb2gray\n","from skimage.io import imread\n","from scipy.cluster.vq import vq\n","from skimage import color, data, exposure, feature, filters, io, transform \n","from matplotlib import pyplot as plt\n","import skimage\n","from skimage import io\n","from sklearn.cluster import MiniBatchKMeans\n","import time\n","\n","import os\n","import gzip"]},{"cell_type":"markdown","metadata":{"id":"ampx9DIJiuGN"},"source":["## Loading dataset\n","\n","We will use 3 categories from Caltech 101 objects dataset for this experiment. Upload the dataset to the drive and mount it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PRSJP1XbG6-a"},"outputs":[],"source":["# modify the dataset variable with the path from your drive\n","dataset_path = r'/content/drive/MyDrive/MAI/CV/2021/Lab_CV/LAB8/p4_2_image_classification_using_BoVW/101_ObjectCategories'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fNoe7u755X6Q"},"outputs":[],"source":["categories = ['butterfly', 'kangaroo', 'dalmatian']\n","ncl = len(categories) * 10"]},{"cell_type":"code","source":["#Function to load and create the dataset\n","import cv2\n","import random\n","\n","dataset_img = []\n","img_size = 224\n","def create_datasetOne():\n","    for category in categories:\n","        path = os.path.join(dataset_path,category)  #Path to images in categories\n","        #categories = ['butterfly'=0 , 'kangaroo'= 1, 'dalmatian' = 2]\n","        class_num = categories.index(category)\n","        for img in os.listdir(path):\n","          try:\n","            img_array = cv2.imread(os.path.join(path,img))\n","            img_dataset = cv2.resize(img_array,(img_size,img_size))\n","            dataset_img.append([img_dataset,class_num])\n","          except Exception as e:\n","            pass  \n","    # Shuffle the dataset\n","    random.shuffle(dataset_img)         \n","\n","create_datasetOne()"],"metadata":{"id":"nsTsFIK7SarR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gxY0mDoK5EQj"},"source":["*   Create a list of file and the corresponding labels"]},{"cell_type":"code","source":["x = []\n","y = []\n","for features, label in dataset_img:\n","  x.append(features)\n","  y.append(label)\n","\n","x = np.array(x).reshape(-1,img_size,img_size,3).astype('float32')/255\n","#x = np.array(x).astype('float32')\n","y = np.array(y).astype('float32')\n","print(f'The dimension of the dataset is : {x.shape}') "],"metadata":{"id":"vW8NqdnPcqjx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XgVhdjYz5Zhs"},"source":["*   Create a train / test split where the test is 10% of the total data"]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","x_train, x_test, x_label_train, x_label_test = train_test_split(x, y, test_size=0.1)\n","print(x_train.shape)\n","print(x_test.shape)\n","print(x_label_train.shape)\n","print(x_label_test.shape)"],"metadata":{"id":"b7h7trcjczoi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_Hl36Ej_5k6Y"},"source":["*   How do you select the train/test split?"]},{"cell_type":"markdown","metadata":{"id":"-aOe27Kx5vtd"},"source":["**Solution**\n","\n","*Using the **train_test_split** function. The images have been previously shuffled randomly so that they are now picked in no specific order.*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"18OZf2kfkVNB"},"source":["## Feature Extraction using ORB\n","\n","The first step is to extract descriptors for each image in our dataset. We will use ORB to extract descriptors.\n","\n","*   Create ORB detector with 256 keypoints.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ptLbPcoow-ar"},"outputs":[],"source":["# solution\n","n_kp = 256\n","descriptor_extractor = ORB(n_keypoints=n_kp)"]},{"cell_type":"markdown","metadata":{"id":"3yinPkL8brow"},"source":["*   Extract ORB descriptors from all the images in the train set.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PCiXJeLFxGtP"},"outputs":[],"source":["# solution\n","import cv2\n","\n","desc_all_ORB = []\n","for i in range(len(x_train)):\n","  # We extract the descriptors for each image\n","  #img = rgb2gray(x_train[i])\n","  img = cv2.cvtColor(x_train[i], cv2.COLOR_BGR2GRAY)\n","  descriptor_extractor.detect_and_extract(img) \n","  descriptors = descriptor_extractor.descriptors\n","  # Save the descriptors in an global matrix\n","  desc_all_ORB.append(descriptors)\n","\n","no_err_train = [i for i, v in enumerate(desc_all_ORB) if v.shape[0] != 256]\n","\n","for ind in no_err_train:\n","    del desc_all_ORB[ind]\n","    x_train = np.delete(x_train, ind)\n","    x_label_train = np.delete(x_label_train, ind)\n","\n","print(np.array(desc_all_ORB).shape)\n","print(x_train.shape)\n","print(x_label_train.shape)"]},{"cell_type":"code","source":["descriptor_list_train = np.array(desc_all_ORB).reshape(x_train.shape[0]*x_train.shape[1],x_train.shape[2])"],"metadata":{"id":"UzJIDLhvpgsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# solution\n","import cv2\n","\n","desc_all_ORB_test = []\n","for i in range(len(x_test)):\n","  # We extract the descriptors for each image\n","  img = cv2.cvtColor(x_test[i], cv2.COLOR_BGR2GRAY)\n","  descriptor_extractor.detect_and_extract(img) \n","  descriptors = descriptor_extractor.descriptors\n","  # Save the descriptors in an global matrix\n","  desc_all_ORB_test.append(descriptors)\n","\n","no_err_test = [i for i, v in enumerate(desc_all_ORB_test) if v.shape[0] != 256]\n","\n","for ind in no_err_test:\n","    del desc_all_ORB_test[ind]\n","    x_test = np.delete(x_test, ind)\n","    x_label_test = np.delete(x_label_test, ind)\n","\n","print(np.array(desc_all_ORB_test).shape)\n","print(x_test.shape)\n","print(x_label_test.shape)\n","\n","descriptor_list_test = np.array(desc_all_ORB_test).reshape(219*256,256)"],"metadata":{"id":"yQDjAGYLWtrT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GJehFdyt583b"},"source":["*   What is the size of the feature descriptors? What does each dimension represent in the feature descriptors?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bzTspvF96LeC"},"outputs":[],"source":["# solution\n","print(f'Descriptors generate with exit, the size of the descriptors is {len(desc_all_ORB)}')  \n","print(np.array(desc_all_ORB).shape)"]},{"cell_type":"markdown","metadata":{"id":"MNFOjsRj6PGk"},"source":["**Solution**\n","\n","*For each image in the dataset, we look for 256 keypoints, each of which has an associated descriptor to it. The ORB detector uses binary descriptors, that is, vectors of Boolean type which in our case are of length 256.*\n","\n","*Because there are 256 keypoints per image and we are taking 219 images for the train set, the size of the variable ('desc_all_ORB') that contains all of the descriptors is then: (219, 256, 256).*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"420YQkAzleTQ"},"source":["### Codebook Construction\n","\n","Codewords are nothing but vector representation of similar patches. This codeword produces a codebook similar to a word dictionary. We will create the codebook using K-Means algorithm\n","\n","*   Create a codebook using K-Means with k=number_of_classes*10\n","*   Hint: Use sklearn.cluster.MiniBatchKMeans for K-Means"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iO0e4718ppJt"},"outputs":[],"source":["# Reshape the dataset to have a list with all the descriptors (n_descriptors = n_images x n_keypoints)\n","X = desc_all_ORB[0]\n","for i in range(1,len(x_train)):\n","  X = np.vstack((X,desc_all_ORB[i]))\n","# Convert list to array\n","X = np.array(X)\n","X.shape\n","\n"]},{"cell_type":"code","source":["descriptor_list_train = np.array(desc_all_ORB).reshape(219*256,256)"],"metadata":{"id":"-6BJnzji_wah"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x4QaL135tyIc"},"outputs":[],"source":["# solution\n","from sklearn.feature_extraction.image import extract_patches_2d\n","\n","K = 3*10\n","kmeans = MiniBatchKMeans(n_clusters=K)#,batch_size=6,max_iter=10)\n","kmeans.fit(descriptor_list_train)\n","codebook = kmeans.cluster_centers_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Owytz0Bzsxl5"},"outputs":[],"source":["np.array(codebook).shape\n","# Each cluster center produced by k-means becomes a codevector, so we have 30 codevectors\n","# If we compare the codebook to a dictionary, each codevector represents one \"word\" in our Bag of Words"]},{"cell_type":"markdown","metadata":{"id":"d16vgCvrRLO1"},"source":["*   Create a histogram using the cluster centers for each image descriptor.\n","    *   Remember the histogram would be of size *n_images x n_clusters*."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tIJod5HqSZri"},"outputs":[],"source":["# 1. Graphic histograms for every image in the treining set (219 images x 30 clusters)\n","import matplotlib.pyplot as plt\n","\n","Y_train = kmeans.predict(descriptor_list_train)\n","\n","histogram, ax = plt.subplots(1,len(x_train),figsize=(600,2))\n","for i in range(len(x_train)):\n","  ax[i].hist(Y_train[i*n_kp:(i+1)*n_kp], bins = K, color='magenta')\n","  ax[i].set_ylim([0, n_kp])\n","  ax[i].set_title(\"Fig. \"+str(i+1))\n","\n","for ax in histogram.get_axes():\n","    ax.label_outer()\n","plt.show()\n","\n","# Representation of the images in the training set\n","images, axis = plt.subplots(1,len(x_train),figsize=(600,2))\n","for i in range(len(x_train)):\n","  d = (dataset_path+'/'+x_train[i])\n","  img = io.imread(d)\n","  axis[i].imshow(img)\n","  axis[i].axes.xaxis.set_visible(False)\n","  axis[i].axes.yaxis.set_visible(False)\n","  axis[i].set_title(x_label_train)\n","  #axis[i].set_title(\"Fig. \"+str(i+1))\n","plt.show()\n","\n","# NOTE: Click on the generated figures to englargen them"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9EbShC5SZ0i"},"outputs":[],"source":["# 2. Histogram matrix (219 images x 30 clusters)\n","histMatrix = np.zeros((len(x_train),K),\"int32\")\n","for i in range(len(x_train)):\n","  for j in range(n_kp):\n","    for k in range(K):\n","      if Y_train[i*n_kp+j]==k+1:\n","        histMatrix[i,k]+=1\n","\n","from sklearn.preprocessing import StandardScaler\n","histMatrix = StandardScaler().fit_transform(histMatrix) # normalize the histogram matrix"]},{"cell_type":"markdown","metadata":{"id":"jmRO7dfLjgZa"},"source":["\n","# Creating Classification Model\n","\n","*   The next step is to create a classification model. We will use a C-Support Vector Classification for creating the model.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K7VTBz1Oimtz"},"outputs":[],"source":["from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","\n","\n","# The training-set has 219 figures, with features \n","c_model = SVC(kernel = 'rbf')\n","param_grid = {'C':np.logspace(-3,4,18), 'gamma':np.logspace(-3,2,18)}\n"]},{"cell_type":"markdown","metadata":{"id":"lrit95Ud6pUU"},"source":["*   Use GridSearchCV to find the optimal value of C and Gamma."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lTE9WIzcTGDt"},"outputs":[],"source":["t0 = time.time()\n","classModel = GridSearchCV(c_model, param_grid)\n","classModel.fit(histMatrix,labels_train)\n","X_train = histMatrix\n","\n","print(\"Best parameters set found by GridSearchCV:\")\n","print()\n","print(classModel.best_params_)\n","print(\"Best score:\")\n","print(classModel.best_score_)\n","\n","print(\"--- Program executed in %s seconds ---\" % (time.time() - t0))"]},{"cell_type":"markdown","metadata":{"id":"eqThTmO5j1-p"},"source":["# Testing the Classification Model\n","\n","*   Extract descriptors using ORB for the test split\n","*   Use the previously trained k-means to generate the histogram\n","*   Use the classifier to predict the label\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x2Gzbww9e0pP"},"outputs":[],"source":["# solution\n","\n","# 1. Extract descriptors for the test-set (25 images, 256 descriptors per image):\n","import cv2\n","\n","desc_all_ORB_test = []\n","for i in range(len(x_test)):\n","  # We extract the descriptors for each image\n","  img = cv2.cvtColor(x_test[i], cv2.COLOR_BGR2GRAY)\n","  descriptor_extractor.detect_and_extract(img) \n","  descriptors = descriptor_extractor.descriptors\n","  # Save the descriptors in an global matrix\n","  desc_all_ORB_test.append(descriptors)\n","\n","no_err_test = [i for i, v in enumerate(desc_all_ORB_test) if v.shape[0] != 256]\n","\n","for ind in no_err_test:\n","    del desc_all_ORB_test[ind]\n","    x_test = np.delete(x_test, ind)\n","    x_label_test = np.delete(x_label_test, ind)\n","\n","print(np.array(desc_all_ORB_test).shape)\n","print(x_test.shape)\n","print(x_label_test.shape)"]},{"cell_type":"code","source":["# Reshape the dataset to have a list with all the descriptors (n_descriptors = n_images x n_keypoints)\n","X_test = desc_all_ORB_test[0]\n","for i in range(1,len(x_test)):\n","  X_test = np.vstack((X_test,desc_all_ORB_test[i]))\n","# Convert list to array\n","X_test = np.array(X_test)\n","25*256-25"],"metadata":{"id":"2G7Q_UGlD8TN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["descriptor_list_test = np.array(desc_all_ORB_test).reshape(25*256,256)\n","Y_test = kmeans.predict(descriptor_list_test)\n","\n","# 2. Generate their histograms (25 images x 30 clusters):\n","histMatrix_test = np.zeros((len(x_test),K),\"int32\")\n","for i in range(len(x_test)):\n","  for j in range(n_kp):\n","    for k in range(K):\n","      if Y_test[i*n_kp+j]==k+1:\n","        histMatrix_test[i,k]+=1\n","histMatrix_test = StandardScaler().fit_transform(histMatrix_test) # normalize the histogram matrix\n","\n","# 3. Use the SVC model to predict their labels\n","labels_test_pred = classModel.predict(histMatrix_test)\n"],"metadata":{"id":"vKqchGhLCK3A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gGyQUtU3lAEz"},"source":["*   Calculate the accuracy score for the classification model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PszxSB0Ek_Lt"},"outputs":[],"source":["# solution\n","\n","from sklearn.metrics import accuracy_score\n","print('Accuracy of the classification model is:')\n","print(accuracy_score(labels_test, labels_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"drlq-5AM615_"},"source":["*   Generate the confusion matrix for the classification model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NpqXVYrw61OG"},"outputs":[],"source":["# solution\n","\n","# confusion matrix in sklearn\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import ConfusionMatrixDisplay \n","import seaborn as sns\n","\n","# confusion matrix\n","\n","ConfusionMatrix = confusion_matrix(labels_test, labels_test_pred)\n","ax = sns.heatmap(ConfusionMatrix, annot=True, cmap='Blues')\n","ax.set_title('Confusion matrix for the classification model');\n","ax.set_xlabel('\\nPredicted Values')\n","ax.set_ylabel('Actual Values ');\n","\n","## Display the visualization of the Confusion Matrix.\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"7TN4rRra9yv_"},"source":["*   Why do we use Clustering to create the codebook? \n","*   What are the other techniques that can be used to create the codebook?"]},{"cell_type":"markdown","metadata":{"id":"Ri9kU3wa3Rei"},"source":["**Solution**\n","\n","*Clustering is used to create the codebook so that the descriptors that are very similar among each other can be considered as a single \"visual-word\", instead of having many individual \"words\" that have almos the same meaning (meaning they represent very similar features of the image). By Clustering, we are able to group those visual features that are very close to each other in their own cluster, and approximate them by the center of said cluster.*\n","\n","*For the generation of the codebook other techniques such as the Gaussian Mixture Model can be used too.*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"ll0j8G-oIaHd"},"source":["*   Will adding more keypoints increase the performanc of the algorithm?"]},{"cell_type":"markdown","metadata":{"id":"ka3z1sJVInS5"},"source":["**Solution**\n","\n","* 256 Keypoints --> Accuracy of the classification model is: 0.32*\n","* 500 Keypoints --> Accuracy of the classification model is: 0.32*\n","* 1000 Keypoints --> Accuracy of the classification model is: 0.32*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"K-8E3dBw8Zoa"},"source":["# Extracting features from Deep Network\n","\n","It is quite possible to extract features (similar to SIFT or ORB) from different layers of deep network.\n","\n","*   Load ResNet50 model with imagenet weights and check the summary of the model\n","*   Create a model to extract features from the 'avg_pool' layer.\n","*   Extract features from the layer for all the train images."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"amYPdQKBdHt0"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import os\n","import cv2\n","\n","path_dp = '/content/drive/MyDrive/MAI/CV/2021/Lab_CV/LAB8/p4_2_image_classification_using_BoVW/101_ObjectCategories/'\n","categories = ['butterfly', 'kangaroo', 'dalmatian']\n","ncl = len(categories) * 10\n","\n","for category in categories:\n","  path = os.path.join(path_dp,category)  #Path to images in categories\n","  for img in os.listdir(path):\n","    img_array = cv2.imread(os.path.join(path,img),cv2.IMREAD_GRAYSCALE)\n","    plt.imshow(img_array, cmap='gray')\n","    plt.show()\n","    break\n","  break  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NAPz04JKmKAH"},"outputs":[],"source":["#Resize the images for (224,224)\n","img_size = 224\n","img_dataset = cv2.resize(img_array,(img_size,img_size))\n","plt.imshow(img_dataset,cmap = 'gray')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2QNz8xbImT02"},"outputs":[],"source":["import random\n","from sklearn.model_selection import train_test_split\n","\n","#Function to load and create the dataset\n","\n","dataset_img_nn = []\n","img_size = 224\n","def create_dataset():\n","    for category in categories:\n","        path = os.path.join(path_dp,category)  #Path to images in categories\n","        #categories = ['butterfly'=0 , 'kangaroo'= 1, 'dalmatian' = 2]\n","        class_num = categories.index(category)\n","        for img in os.listdir(path):\n","          try:\n","            img_array = cv2.imread(os.path.join(path,img))\n","            img_dataset = cv2.resize(img_array,(img_size,img_size))\n","            dataset_img_nn.append([img_dataset,class_num])\n","          except Exception as e:\n","            pass  \n","    # Shuffle the dataset\n","    random.shuffle(dataset_img_nn)         \n","\n","create_dataset()\n","\n","x_nn = []\n","y_nn = []\n","for features, label in dataset_img_nn:\n","  x_nn.append(features)\n","  y_nn.append(label)\n","\n","\n","\n","x_nn = np.array(x_nn).reshape(-1,img_size,img_size,3).astype('float32')/255\n","y_nn = np.array(y_nn).astype('float32')\n","print(f'The dimension of the dataset is : {x_nn.shape}') \n","\n","\n","x_train_nn, x_test_nn = train_test_split(x_nn, test_size=0.1)\n","x_label_train_nn, x_label_test_nn = train_test_split(y_nn, test_size=0.1)\n","print(x_train_nn.shape)\n","print(x_test_nn.shape)\n","print(x_label_train_nn.shape)\n","print(x_label_test_nn.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_Kk0OSrULBX"},"outputs":[],"source":["import pickle\n","\n","pickle_out = open('x_nn.pickle','wb')\n","pickle.dump(x_nn, pickle_out)\n","pickle_out.close()\n","\n","pickle_out = open('y_nn.pickle','wb')\n","pickle.dump(y_nn, pickle_out)\n","pickle_out.close()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Yxzmn9wCVXT7"},"outputs":[],"source":["pickle_in = open('x_nn.pickle','rb')\n","X = pickle.load(pickle_in)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1UkYr94IWT-s"},"outputs":[],"source":["X = pickle.load(open('x_nn.pickle','rb'))\n","Y = pickle.load(open('y_nn.pickle','rb'))\n","\n","X_train_nn, X_test_nn = train_test_split(X, test_size=0.1, random_state=42)\n","print(X_train_nn.shape)\n","print(X_test_nn.shape)"]},{"cell_type":"markdown","metadata":{"id":"RGH76qRuDBV8"},"source":["## Load ResNet50 model with imagenet weights and check the summary of the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YVv5J6-OWdQd"},"outputs":[],"source":["# Load ResNet50 model with imagenet weights and check the summary of the model\n","import tensorflow as tf\n","import keras\n","\n","model = tf.keras.applications.ResNet50(weights=\"imagenet\")\n","#model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FijKProMDNEQ"},"outputs":[],"source":["# Create a model to extract features from the 'avg_pool' layer\n","model_Resnet = tf.keras.applications.ResNet50(\n","    weights = \"imagenet\", #Load weights pre-trained on ImageNet\n","    input_shape =(224,224,3),\n","    include_top = False,\n",")# Do not include the ImageNet classifier at the top."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fsV0wi6dW72o"},"outputs":[],"source":["# Extract features from the layer for all the train images:\n","extracted_features = model_Resnet.predict(x_train_nn)"]},{"cell_type":"markdown","metadata":{"id":"HFN1GjP-7IJ4"},"source":["*   What is the size of the feature descriptors?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GCbFj-8fieht"},"outputs":[],"source":["print('Shape of the features as extracted from the network:')\n","print(extracted_features.shape)\n","features = extracted_features.reshape(extracted_features.shape[0]*extracted_features.shape[1]*extracted_features.shape[2],extracted_features.shape[3])\n","print('Number of descriptors per image:')\n","n_descriptors_nn = features.shape[0]//len(x_train)\n","print(n_descriptors_nn)\n","print('Size of each descriptor:')\n","print(features.shape[1])"]},{"cell_type":"markdown","metadata":{"id":"GkEprqtK87q2"},"source":["*   Create codebook using the extracted features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5crz4gBz9CQF"},"outputs":[],"source":["# solution\n","from sklearn.feature_extraction.image import extract_patches_2d\n","\n","K = 3*10\n","kmeans_nn = MiniBatchKMeans(n_clusters=K,random_state=0,batch_size=6,max_iter=10)\n","kmeans_nn.fit(features)\n","codebook_nn = kmeans_nn.cluster_centers_\n","np.array(codebook_nn).shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rs3znKvTEAJy"},"outputs":[],"source":["# 2. Histogram matrix (219 images x 30 clusters)\n","Y_nn = kmeans_nn.predict(features)\n","\n","histMatrix_train_nn = np.zeros((len(x_train),K),\"int32\")\n","for i in range(len(x_train)):\n","  for j in range(n_descriptors_nn):\n","    for k in range(K):\n","      if Y_nn[i*n_descriptors_nn+j]==k+1:\n","        histMatrix_train_nn[i,k]+=1\n","\n","from sklearn.preprocessing import StandardScaler\n","histMatrix_train_nn = StandardScaler().fit_transform(histMatrix_train_nn) # normalize the histogram matrix\n","print(histMatrix_train_nn.shape)\n","print(x_label_train_nn.shape)"]},{"cell_type":"markdown","metadata":{"id":"K_RB2vPl9CzB"},"source":["*   Train SVM classifier using the codebook"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5oKk_Wzz9HLf"},"outputs":[],"source":["# solution x_label_train_nn\n","\n","from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","\n","Y_features = kmeans_nn.predict(features)\n","\n","c_model_nn = SVC(kernel = 'rbf')\n","param_grid_nn = {'C':np.logspace(-3,3,50), 'gamma':np.logspace(-4,1,50)}\n","\n","#param_grid = {'C': [1, 10, 100, 1000, 10000], 'gamma': [0.001, 0.0001, 0.00001]}\n","classModel_nn = GridSearchCV(c_model_nn, param_grid_nn)\n","classModel_nn.fit(histMatrix_train_nn,x_label_train_nn) # The training-set has 219 figures, with 30 features each\n","\n","print(\"Best parameters set found by GridSearchCV:\")\n","print()\n","print(classModel_nn.best_params_)"]},{"cell_type":"markdown","metadata":{"id":"ym0XesGL9Hrc"},"source":["*   Evaluate the test set using the above method"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NM6LIynq9Ma1"},"outputs":[],"source":["# solution\n","#Extract features from test dataset:\n","extracted_features_test = model_Resnet.predict(x_test_nn)\n","features_test = extracted_features_test.reshape(extracted_features_test.shape[0]*extracted_features_test.shape[1]*extracted_features_test.shape[2],extracted_features_test.shape[3])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lXZ6CQPPP-FL"},"outputs":[],"source":["#Histogram matrix of the extracted features from the test set:\n","Y_test_nn = kmeans_nn.predict(features_test)\n","\n","histMatrix_test_nn = np.zeros((len(x_test),K),\"int32\")\n","for i in range(len(x_test)):\n","  for j in range(n_descriptors_nn):\n","    for k in range(K):\n","      if Y_test_nn[i*n_descriptors_nn+j]==k+1:\n","        histMatrix_test_nn[i,k]+=1\n","\n","from sklearn.preprocessing import StandardScaler\n","histMatrix_test_nn = StandardScaler().fit_transform(histMatrix_test_nn) # normalize the histogram matrix\n","print(histMatrix_test_nn.shape)\n","print(x_label_test_nn.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UiBeQGD2P-T6"},"outputs":[],"source":["#Use the SVC model to predict the labels of the test set:\n","labels_test_pred_nn = classModel_nn.predict(histMatrix_test)"]},{"cell_type":"markdown","metadata":{"id":"d-OnKf-ti_vy"},"source":["*   Calculate the accuracy score and confusion matrix for the classification model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"upqdRQUoGC94"},"outputs":[],"source":["# solution\n","from sklearn.metrics import accuracy_score\n","print('Accuracy of the classification model is:')\n","print(accuracy_score(x_label_test_nn, labels_test_pred_nn))"]},{"cell_type":"markdown","metadata":{"id":"eafGx0Hv9M6p"},"source":["*   Compare the performance of both the BoVW models. Which model works better and why?"]},{"cell_type":"markdown","metadata":{"id":"U9SOuiKwiXkr"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"8BuiFGxPjDb1"},"source":["*   Can the performance of pre-trained model increased further? If so, how?"]},{"cell_type":"markdown","metadata":{"id":"0kuJnOb9jE9r"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"jQlPanaIIMKV"},"source":["*   What happens if the test image does not belong to any of the trained classes?"]},{"cell_type":"markdown","metadata":{"id":"5UEnEFDdISFJ"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"Z-sxoswiJGTQ"},"source":["*   Combine the features extracted using ORB and Deep Neural Network.\n","*   Create a codebook with the combined features\n","*   Train a SVM classifier using the generated codebook and evaluate the performance using accuracy and confusion matrix."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5Xgv3caJf6X"},"outputs":[],"source":["# solution\n","\n"]},{"cell_type":"markdown","metadata":{"id":"i2iBPUZTJhju"},"source":["*   Do the combined features increase the performance of the classifier?"]},{"cell_type":"markdown","metadata":{"id":"ZYG_4SReJg2A"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"DjL0oQCumkrV"},"source":["## t-distributed Stochastic Neighbor Embedding (Optional).\n","\n","In order to visualize the features of a higher dimension data, t-SNE is used. t-SNE converts the affinities of the data points to probabilities. It recreates the probability distribution in a low-dimensional space. It is very helpful in visualizing features of different layers in a neural network.\n","\n","You can find more information about t-SNE [here](https://scikit-learn.org/stable/modules/manifold.html#t-distributed-stochastic-neighbor-embedding-t-sne)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ahIG1fulhW9"},"outputs":[],"source":["from sklearn.manifold import TSNE\n","\n","model = TSNE(n_components=2, random_state=0)\n","\n","np.set_printoptions(suppress=True)\n","\n","low_embedding = model.fit_transform(dictionary) \n","\n","plt.figure(figsize=(20,10))\n","plt.scatter(low_embedding[:, 0], low_embedding[:, 1], c=y_train)\n","plt.title(\"TSNE visualization\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"3_HR5GjFpjik"},"source":["*   What do you infer from the t-SNE plot?"]},{"cell_type":"markdown","metadata":{"id":"ueY9rvGBrVIc"},"source":["**Solution**\n","\n","*(Double-click or enter to edit)*\n","\n","..."]},{"cell_type":"markdown","metadata":{"id":"NnN_t5Me7N5O"},"source":["\n","---\n","\n","## **End of P4_2: Image Classification using Bag of Visual Words**\n","Deadline for P4_2 submission in CampusVirtual is: **Monday, the 13th of December, 2021**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MjlcF_oDJOmW"},"outputs":[],"source":["## Transfer learning\n","from keras.models import load_model\n","from keras.layers import Lambda\n","import tensorflow as tf\n","import keras\n","\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Flatten\n","\n","# solution  Load ResNet50 model with imagenet weights and check the summary of the model\n","\n","base_model = tf.keras.applications.ResNet50(\n","    weights = \"imagenet\", #Load weights pre-trained on ImageNet\n","    input_shape =(224,224,3),\n","    include_top = False,\n",")# Do not include the ImageNet classifier at the top.\n","\n","base_model.trainable = False      # First we freeze the model\n","\n","# Create new model on top\n","#inputs = keras.Input(shape=(224, 224, 3))\n","\n","# add a global spatial average pooling layer\n","\n","x = base_model.output\n","\n","\n","# Create a model to extract features from the 'avg_pool' layer.\n","#x = keras.layers.GlobalAveragePooling2D()(x) #Extra\n","x = keras.layers.GlobalAveragePooling2D(name='avg_pool')(x)\n","\n","\n","x = Dense(1024, activation='relu')(x)\n","x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n","# and a logistic layer -- let's say we have 3 classes\n","predictions = Dense(1, activation='sigmoid')(x)\n","\n","# this is the model we will train\n","model = Model(inputs=base_model.input, outputs=predictions)\n","model.summary()\n","\n","\n","\n","\n","\n","\n","\n","model.compile(\n","    optimizer = tf.keras.optimizers.Adam(),\n","    loss = keras.losses.BinaryCrossentropy(from_logits=True),\n","    metrics = [keras.metrics.BinaryAccuracy()],\n",")\n","epochs = 10\n","\n","\n","\n","\n","model.fit(x_nn,y_nn,batch_size=32, epochs = epochs,validation_split=0.1)\n"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copy of p4_2_image_classification_using_BoVW_EdisonJairBejaranoSepulveda.ipynb","provenance":[],"private_outputs":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}