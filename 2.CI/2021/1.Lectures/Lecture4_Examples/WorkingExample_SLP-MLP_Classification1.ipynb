{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a Modified Copy of the Basic Example\n",
    "\n",
    "This is a modified copy of the basic example of a Single and Multilayer Perceptron for Classification and Regression.\n",
    "\n",
    "It will allow to test different scenarios by changing the global variables at the beginning of the script.\n",
    "\n",
    "**TO SIMPLIFY, ONLY CLASSIFICATION PROBLEMS ARE TESTED**\n",
    "\n",
    "**This script has been tested with the following package versions:**\n",
    "- pandas 1.3.3\n",
    "- sklearn 0.24.0\n",
    "- keras 2.2.4 + tensorflow 1.14.0 / keras 2.6.0 + tensorflow 2.6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a list of things that you can test:\n",
    "- Check that the results can be very different:\n",
    "  - For different runs with the same parameters (non-linear networks)\n",
    "  - By changing the value of several data parameters:\n",
    "    - TRAIN\\_SIZE\\_PCT\\_SPLIT: 0.70,0.50,0.20,0.05,0.01 (ionosphere, MLP-100-50, SGD, LR = 0.01)\n",
    "    - SCALE\\_INPUTS\\_FUNCTION (hepatits, linear or non-linear networks)\n",
    "  - By changing the value of several critical training parameters (ionosphere, MLP-100-50):\n",
    "    - TRAINING\\_ALGORITHM: SGD, RMSprop, Adam\n",
    "    - LEARNING\\_RATE: 0.1,0.01,0.001,0.0001\n",
    "    - MOMENTUM\\_RATE: 0.80, 0.00 (SGD, LR = 0.001)\n",
    "    - FACTIVATION\\_HIDDEN1 and FACTIVATION\\_HIDDEN2: tanh, relu (SGD, LR = 0.001)\n",
    "    - FACTIVATION\\_OUTPUT: softmax, linear\n",
    "- Underfitting and overfitting:\n",
    "  - Underfitting:\n",
    "    - Train a linear model and compare with a non-linear one (xor)\n",
    "    - Train a non-linear model with small LR few epochs (ionosphere - MLP-100-50, SGD, LR <= 0.0001, EPOCHS = 200)\n",
    "  - Overfitting:\n",
    "    - Train a non-linear model with large LR few epochs (ionosphere - MLP-100-50, SGD, LR >= 0.01, EPOCHS = 200)\n",
    "    - Train a non-linear model with small LR many epochs (ionosphere - MLP-100-50, SGD, LR <= 0.0001, EPOCHS = 5000)\n",
    "    - Train a non-linear model with many hidden layers (sonar - MLP-20 vs MLP-20-20-20-20-20, SGD, LR = 0.002,   EPOCHS = 200)\n",
    "    - Curse of Dimensionality: small value for TRAIN\\_SIZE\\_PCT\\_SPLIT (ionosphere - MLP-100-50, SGD, LR = 0.01, EPOCHS = 200)\n",
    "- The effect of the noise in the data:\n",
    "  - Add random inputs and labels: NRANDOM_EXAMPLES != 0)\n",
    "  - Add random features: NRANDOM_FEATURES = 1000,10000 (ionosphere - MLP-100-50, SGD, LR = 0.001, EPOCHS = 200)\n",
    "  - Add noise to the inputs: ADD_NOISE_INPUTS = True\n",
    "  - Shuffle the labels: SHUFFLE\\_LABELS = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### First we set the values of several global variables\n",
    "MULTILAYER_PERCEPTRON = False     ### If False, it is a Single-layer Perceptron\n",
    "\n",
    "NRANDOM_EXAMPLES      = 0         ### Number of random examples to add\n",
    "NRANDOM_FEATURES      = 0         ### Number of random features to add\n",
    "ADD_NOISE_INPUTS      = False     ### If True, add standard Gaussian noise to the inputs\n",
    "SHUFFLE_LABELS        = False     ### If True, shuffle the labels (without shuffling the inputs)\n",
    "SCALE_INPUTS_FUNCTION = \"M0SD1\"   ### \"M0SD1\": Mean 0 StdDev 1 / \"MinMax\": Values in an interval / None\n",
    "\n",
    "TRAIN_SIZE_PCT_SPLIT  = 0.70      ### Percentage of data used for training (it must be in (0,1])\n",
    "\n",
    "NHIDDEN1 = 100;  FACTIVATION_HIDDEN1 = 'tanh'\n",
    "NHIDDEN2 = 50;   FACTIVATION_HIDDEN2 = 'tanh'\n",
    "NHIDDEN3 = 0;    FACTIVATION_HIDDEN3 = 'tanh'\n",
    "NHIDDEN4 = 0;    FACTIVATION_HIDDEN4 = 'tanh'\n",
    "NHIDDEN5 = 0;    FACTIVATION_HIDDEN5 = 'tanh'\n",
    "FACTIVATION_OUTPUT = 'softmax'    ### only for CLASSIFICATION\n",
    "\n",
    "TRAINING_ALGORITHM = \"SGD\"        ### \"SGD\", \"RMSprop\", \"Adam\"\n",
    "\n",
    "LEARNING_RATE      = 0.01         ### (almost) ALL training algorithms have a learning rate\n",
    "MOMENTUM_RATE      = 0.80         ### Maybe not needed in some training algorithms\n",
    "\n",
    "BATCHSIZE          = 20           ### Mini-batch size\n",
    "NEPOCHS            = 200          ### Number of training iterations\n",
    "\n",
    "inputsFileName = 'Data/ionosphere.inputs'\n",
    "labelsFileName = 'Data/ionosphere.labels'\n",
    "#inputsFileName = 'Data/hepatitis.inputs'\n",
    "#labelsFileName = 'Data/hepatitis.labels'\n",
    "#inputsFileName = 'Data/sonar.inputs'\n",
    "#labelsFileName = 'Data/sonar.labels'\n",
    "#inputsFileName = 'Data/xor.inputs'\n",
    "#labelsFileName = 'Data/xor.labels'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataFunctions                ### Functions for data management\n",
    "import numpy                        ### Library for numerical computations\n",
    "import keras, tensorflow, sklearn   ### Libraries for constructing and training the models\n",
    "import matplotlib.pyplot as plt     ### Library for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inputs and labels, change (if required)  and preprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Now we read inputs and labels\n",
    "x, y = DataFunctions.loadDatasetsFromFiles (inputsFileName, labelsFileName)\n",
    "y    = y.ravel()   ### sklearn prefers shapes (N,) than (N,1)\n",
    "\n",
    "### Maybe we want to add random examples\n",
    "if NRANDOM_EXAMPLES != 0:\n",
    "    xx = numpy.random.rand(NRANDOM_EXAMPLES,x.shape[1])\n",
    "    x  = numpy.vstack([x, xx])\n",
    "    yy = numpy.random.randint(numpy.min(y),numpy.max(y)+1,NRANDOM_EXAMPLES)\n",
    "    y  = numpy.hstack([y, yy])\n",
    "\n",
    "### Maybe we want to add random features\n",
    "if NRANDOM_FEATURES != 0:\n",
    "    xx = numpy.random.rand(x.shape[0],NRANDOM_FEATURES)\n",
    "    x  = numpy.hstack([x, xx])\n",
    "\n",
    "### Maybe we want to add noise to the data\n",
    "if ADD_NOISE_INPUTS:\n",
    "    x += numpy.random.randn(x.shape[0],x.shape[1])\n",
    "\n",
    "### Maybe we want to shuffle the labels\n",
    "if SHUFFLE_LABELS:\n",
    "    random.shuffle(y)\n",
    "\n",
    "nExamples = x.shape[0]\n",
    "nFeatures = x.shape[1]\n",
    "nClasses  = len(numpy.unique(y))                   ### only for CLASSIFICATION\n",
    "\n",
    "### Convert labels to a 1-of-C (one-hot) scheme\n",
    "## For neural networks, it is easier to output yes/no than (for example) an integer with the predicted class\n",
    "y1C = DataFunctions.convertLabels_1ofC_Scheme (y)  ### only for CLASSIFICATION\n",
    "    \n",
    "### Scale inputs\n",
    "if   SCALE_INPUTS_FUNCTION == \"M0SD1\":\n",
    "    x, Scaler = DataFunctions.scaleDataMean0Dev1Scaler (x)\n",
    "elif SCALE_INPUTS_FUNCTION == \"MinMax\":\n",
    "    x, Scaler = DataFunctions.scaleDataMinMaxScaler (x, FeatureRange=(-1,+1))\n",
    "#print(\"First 3 rows of x:\"); print(x[0:3,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data and labels into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data into training (to construct the model) and test (to estimate the generalization)\n",
    "from sklearn import model_selection\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "  model_selection.train_test_split (x, y, train_size=TRAIN_SIZE_PCT_SPLIT, shuffle=True, stratify=y)\n",
    "y1C_train = DataFunctions.convertLabels_1ofC_Scheme (y_train)  ### only for CLASSIFICATION\n",
    "y1C_test  = DataFunctions.convertLabels_1ofC_Scheme (y_test)   ### only for CLASSIFICATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the architecture (Type of Problem + Model Representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### https://keras.io/api/models/sequential/#sequential-class\n",
    "###\n",
    "\n",
    "### First we indicate that it is a sequential model\n",
    "myNetwork = keras.Sequential()\n",
    "\n",
    "### We need to indicate the input dimension in the first layer\n",
    "inputDimension  = nFeatures\n",
    "outputDimension = nClasses    ### only for CLASSIFICATION\n",
    "\n",
    "if MULTILAYER_PERCEPTRON:\n",
    "\n",
    "    ### Now we add the hidden layers\n",
    "    myNetwork.add ( keras.layers.Dense (NHIDDEN1, activation=FACTIVATION_HIDDEN1, input_dim=inputDimension) )\n",
    "    #myNetwork.add ( keras.layers.Dense (NHIDDEN1, activation=FACTIVATION_HIDDEN1, kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01), input_dim=nFeatures) )\n",
    "    if NHIDDEN2 != 0:\n",
    "        myNetwork.add ( keras.layers.Dense (NHIDDEN2, activation=FACTIVATION_HIDDEN2) )\n",
    "        #myNetwork.add ( keras.layers.Dense (NHIDDEN2, activation=FACTIVATION_HIDDEN2 kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01)) )\n",
    "    if NHIDDEN3 != 0:\n",
    "        myNetwork.add ( keras.layers.Dense (NHIDDEN3, activation=FACTIVATION_HIDDEN3) )\n",
    "        #myNetwork.add ( keras.layers.Dense (NHIDDEN3, activation=FACTIVATION_HIDDEN3 kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01)) )\n",
    "    if NHIDDEN4 != 0:\n",
    "        myNetwork.add ( keras.layers.Dense (NHIDDEN4, activation=FACTIVATION_HIDDEN4) )\n",
    "        #myNetwork.add ( keras.layers.Dense (NHIDDEN4, activation=FACTIVATION_HIDDEN4 kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01)) )\n",
    "    if NHIDDEN5 != 0:\n",
    "        myNetwork.add ( keras.layers.Dense (NHIDDEN5, activation=FACTIVATION_HIDDEN5) )\n",
    "        #myNetwork.add ( keras.layers.Dense (NHIDDEN5, activation=FACTIVATION_HIDDEN5 kernel_regularizer=keras.regularizers.l2(0.01), bias_regularizer=keras.regularizers.l2(0.01)) )\n",
    "\n",
    "    ### And finally we add the output layer\n",
    "    myNetwork.add ( keras.layers.Dense (outputDimension, activation=FACTIVATION_OUTPUT) )\n",
    "\n",
    "else:\n",
    "\n",
    "    ### We only have an output layer\n",
    "    myNetwork.add ( keras.layers.Dense (outputDimension, activation=FACTIVATION_OUTPUT, input_dim=inputDimension) )\n",
    "\n",
    "### Print statistics\n",
    "print(myNetwork.summary())\n",
    "\n",
    "### Now we create a keras model\n",
    "myInput = keras.layers.Input (shape=(nFeatures,))\n",
    "myModel = keras.models.Model (inputs=myInput, outputs=myNetwork(myInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the variables for training: loss function, training algorithm, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Loss function\n",
    "## Usual loss functions: 'categorical_crossentropy' 'binary_crossentropy' 'mean_squared_error', etc\n",
    "lossFunction = ['categorical_crossentropy']   ### only for CLASSIFICATION (for one-hot labels, use categorical_crossentropy)\n",
    "\n",
    "#print(keras.__version__)\n",
    "if keras.__version__ == \"2.2.4\":\n",
    "    optimizers = keras.optimizers\n",
    "else:\n",
    "    optimizers = tensorflow.keras.optimizers\n",
    "\n",
    "### Training algorithm\n",
    "## Every training algorithm will have its own parameters\n",
    "if   TRAINING_ALGORITHM == \"SGD\":\n",
    "    trainAlgorithm = optimizers.SGD (lr=LEARNING_RATE, momentum=MOMENTUM_RATE)  # There are more parameters\n",
    "elif TRAINING_ALGORITHM == \"RMSprop\":\n",
    "    trainAlgorithm = optimizers.RMSprop (lr=LEARNING_RATE)                      # There are more parameters\n",
    "elif TRAINING_ALGORITHM == \"Adam\":\n",
    "    trainAlgorithm = optimizers.Adam (lr=LEARNING_RATE)                         # There are more parameters\n",
    "\n",
    "### Metrics to monitorize\n",
    "## Keras allows to monitorize several metrics along training\n",
    "showMetrics = ['categorical_accuracy', 'mean_squared_error']   ### only for CLASSIFICATION (for one-hot labels, use categorical_accuracy)\n",
    "\n",
    "### Compile the model with all the elements (this is the standard way to work in keras)\n",
    "myModel.compile (loss=lossFunction, optimizer=trainAlgorithm, metrics=showMetrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model with the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "### This method has many parameters:\n",
    "###   https://keras.io/api/models/model_training_apis/#fit-method\n",
    "###\n",
    "\n",
    "validationData = (x_test,y1C_test)  ### We could also use the validation_split parameter\n",
    "fitData = myModel.fit \\\n",
    "  (x_train, y1C_train, validation_data=validationData, batch_size=BATCHSIZE, epochs=NEPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model in the training and test data at the end of the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoresTrain = myModel.evaluate (x_train,y1C_train)\n",
    "scoresTest  = myModel.evaluate (x_test,y1C_test)\n",
    "print(\"Loss function and Accuracy in the training set: %.8f  %7.3f%%\" % (scoresTrain[0], 100*scoresTrain[1])) \n",
    "print(\"Loss function and Accuracy in the test set:     %.8f  %7.3f%%\" % (scoresTest[0],  100*scoresTest[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can plot the training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossTrain = fitData.history[\"loss\"]\n",
    "lossValid = fitData.history[\"val_loss\"]\n",
    "\n",
    "epochsPlot = range(1,len(lossTrain)+1)\n",
    "\n",
    "plt.plot(epochsPlot,lossTrain,label='Training Loss')\n",
    "plt.plot(epochsPlot,lossValid,label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyTrain = fitData.history[\"categorical_accuracy\"]\n",
    "accuracyValid = fitData.history[\"val_categorical_accuracy\"]\n",
    "\n",
    "epochsPlot = range(1,len(accuracyTrain)+1)\n",
    "\n",
    "plt.plot(epochsPlot,accuracyTrain,label='Training Accuracy')\n",
    "plt.plot(epochsPlot,accuracyValid,label='Validation Accuracy')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
