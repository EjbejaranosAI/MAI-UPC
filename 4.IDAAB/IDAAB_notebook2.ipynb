{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "\n",
    "<small><i>Updated January 2022</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<h2>Outline</h2>\n",
    "<ol>\n",
    "    <li>What is a recommender system?</li>\n",
    "    <li>How to build a recommender system? </li>\n",
    "    <li>How to evaluate its success?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to build a recommender system:\n",
    "<ol>\n",
    "    <li>Data collection and understanding</li>\n",
    "    <li>Data filtering/cleaning</li>\n",
    "    <li>Learning<br>\n",
    "        <span style=\"font-size:smaller\">E.g., using item/user similarity function</span></li>\n",
    "    <li>Evaluation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Recommenders\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "    <h3>Non-Personalized filtering</h3><br/>\n",
    "    Based on general information about the items without using any data from the user who receives the recoomendation. \n",
    "</div>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "    <h3>Content-based filtering</h3><br/>\n",
    "    Based on items' descriptions and a profile of user’s preferences. They recommend items which are similar to the ones that the user likes.\n",
    "    <br>We usually need to compute the <b>similarity between items</b> based on their description.\n",
    "        <img src=https://miro.medium.com/max/1334/1*jVG54DFcmaWeJPuJxbGH3w.png width=400>\n",
    "        <center><small>By Nafeea Afshin at <a href=https://nafeea3000.medium.com/recommender-systems-c8db209dd0d3>medium.com</a></small></center>\n",
    "</div>\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "        <h3>Collaborative filtering</h3><br/>\n",
    "        Based on users’ behavior, activities and preferences. Requires a <b>community of users</b>.\n",
    "        <br><b>Hypothesis: Similar users tend to like similar items.</b>\n",
    "        <br>\n",
    "        <br>There are two main types: \n",
    "    <ul>\n",
    "        <li><b>User-based CF</b>: given a user U, find a set of users S which are similar to user U. Then, use the ratings from users in S to make predictions for the user U.</li><br>\n",
    "        <li><b>Item-based CF</b>: build an item-item similarity matrix (measure similarity between all pairs of items). Then, use this matrix to find items similar to the ones already liked by the user.</li>\n",
    "        </ul>\n",
    "    Similarity in both cases can be defined in terms of similar ratings.\n",
    "        <img src=https://miro.medium.com/max/4800/1*Mlt-6jMs0JOHSm9zOTqTDw.jpeg width=700>\n",
    "        <small><center>By Sammit at <a href=https://blog.clairvoyantsoft.com/mlmuse-introduction-to-recommendation-systems-part-i-99dc523b05dc>medium.com</a></center></small>\n",
    "</div>\n",
    "\n",
    "### Summary: \n",
    "<table style=\"width:95%;border:1px solid black;\">\n",
    "  <tr >\n",
    "  <td style=\"width:20%\"></td>\n",
    "  <td>Pros</td>\n",
    "  <td>Cons</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>Content-Based</td>\n",
    "  <td>No community required, comparison between items possible from the beginning</td>\n",
    "  <td>Content description needed; Good explainability, no surprises</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>Collaborative filtering</td>\n",
    "  <td>Well-understood, works well in several domains; easy to implement</td>\n",
    "  <td>Requires a community of users; sparsity problems; difficult to explain suggestions; cold-start problem (for new users and items)</td>\n",
    "  </tr>\n",
    "\n",
    " </table>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-success\" style = \"border-radius:10px;border-width:3px;border-color:darkgreen;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "        <h3>Hybrid solutions</h3><br/>\n",
    "        Hybrid approaches build models that combine somehow content-based and collaborative-based recsys.\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Hands on\n",
    "## A User-Based Collaborative Filtering RecSys for Movielens\n",
    "\n",
    "Given a user (Marta) and an item that she has not seen, the goal is to estimate her rating for the item. The data that we are going to use in the most basic situation looks as:\n",
    "<table style=\"width:60%\">\n",
    "  <tr>\n",
    "    <td></td>\n",
    "    <td>Superman</td> \n",
    "    <td>Star Wars 1</td>\n",
    "    <td>Matrix</td>\n",
    "    <td>Spiderman</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User1</td>\n",
    "    <td>3.5</td> \n",
    "    <td>4</td>\n",
    "    <td>5</td>\n",
    "    <td>5</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User2</td>\n",
    "    <td>3</td> \n",
    "    <td><font color=\"red\"><b>¿?</b></font></td>\n",
    "    <td>4.5</td>\n",
    "    <td>3</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User3</td>\n",
    "    <td>3.5</td> \n",
    "    <td>5</td>\n",
    "    <td>3.5</td>\n",
    "    <td>2</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>User 4 (Marta)</td>\n",
    "    <td>3</td> \n",
    "    <td>3.5</td>\n",
    "    <td>4.5</td>\n",
    "    <td><font color=\"red\"><b>¿?</b></font></td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use again the MovieLens dataset, which you should have downloaded to complete the first notebook.\n",
    "\n",
    "Let us first load the libraries that we are going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, next, the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The dataset is composed of 3 main files\n",
    "\n",
    "# The users file \n",
    "u_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "# The movies (items) file\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "# It contains aditional columns indicating, among other the movies' genre.\n",
    "# Let's only load the first three columns:\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# The ratings file \n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "\n",
    "# We merge all three dataframes into a single dataset\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "# and keep only the columns that we are going to use\n",
    "data = data[['user_id', 'rating', 'movie_id', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a subset of just 100 users, the ones with a largest number of ratings. We keep a 20% of them for evaluation purposes, and learn with the remaining 80%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (33389, 4)\n",
      "Usuaris: 100\n",
      "Films: 1615\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7) # for replicability\n",
    "\n",
    "# We keep only data regarding the 100 users with the largest number of ratings\n",
    "user_id_most_raters = data.groupby('user_id').size().sort_values(ascending=False).head(100).keys()\n",
    "data = data[data['user_id'].isin(user_id_most_raters)].copy()\n",
    "print('Dataset size:', data.shape)\n",
    "print('Usuaris:', data.user_id.nunique())\n",
    "print('Films:',data.movie_id.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you might infer from the previous CF description, computating similarity between items is critical in CF methods. <br>\n",
    "\n",
    "## Defining a similarity between users\n",
    "\n",
    "In order to define a similarity metric between two users, it makes sense to have a look first to the movies that they both have seen/rated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of movies seen by both users: 98\n",
      "Ratings from user 1\n",
      "                               title_x  rating_x\n",
      "0                         Kolya (1996)         4\n",
      "1  Truth About Cats & Dogs, The (1996)         3\n",
      "2                 Birdcage, The (1996)         3\n",
      "3          English Patient, The (1996)         3\n",
      "4                 Marvin's Room (1996)         3\n",
      "Ratings from user 2\n",
      "                               title_y  rating_y\n",
      "0                         Kolya (1996)         1\n",
      "1  Truth About Cats & Dogs, The (1996)         3\n",
      "2                 Birdcage, The (1996)         5\n",
      "3          English Patient, The (1996)         1\n",
      "4                 Marvin's Room (1996)         2\n"
     ]
    }
   ],
   "source": [
    "# dataframe with the data from a first user\n",
    "data_user_1 = data[data.user_id == data.user_id.unique()[0]]\n",
    "\n",
    "# dataframe with the data from a second user\n",
    "data_user_2 = data[data.user_id == data.user_id.unique()[1]]\n",
    "\n",
    "# merge works as an inner join\n",
    "common_movies = pd.merge(data_user_1, data_user_2, on='movie_id')\n",
    "print(\"\\nNumber of movies seen by both users:\", common_movies.shape[0])\n",
    "\n",
    "print(\"Ratings from user 1\")\n",
    "print(common_movies[['title_x','rating_x']].head(5))\n",
    "print(\"Ratings from user 2\")\n",
    "print(common_movies[['title_y','rating_y']].head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea when measuring similarity between two users, <i>a</i> and <i>b</i>, is to first identify the items that both users have commonly ever rated (<i>P</i>), and then to apply certain (dis)similarity function between their ratings of these commonly rated movies.\n",
    "\n",
    "We can use different (di)similarity functions. For example,\n",
    "<ul>\n",
    "    <li>Euclidean distance    <br>\n",
    "    $$dist(a,b) = \\sqrt{\\sum_{p \\in P}{(r_{a,p} - r_{b,p})^2}}$$\n",
    "which needs to be transformed to work as a similarity measure: $sim(a,b) = (1+dist(a,b))^{-1}$.\n",
    "    </li>\n",
    "    <li>Pearson Correlation</li>\n",
    "    $$sim(a,b) = \\frac{\\sum_{p\\in P} (r_{a,p}-\\bar{r_a})(r_{b,p}-\\bar{r_b})}{\\sqrt{\\sum_{p \\in P}(r_{a,p}-\\bar{r_a})^2}\\sqrt{\\sum_{p \\in P}(r_{b,p}-\\bar{r_b})^2}}$$\n",
    "    <br>\n",
    "    <li>Cosine similarity</li>\n",
    "    $$ sim(a,b) = \\frac{\\vec{a} \\cdot \\vec{b}}{|\\vec{a}| |\\vec{b}|}\n",
    "    =\\frac{\\sum_{p\\in P} r_{a,p} r_{b,p}}{\\sqrt{\\sum_{p\\in P} r^2_{a,p}}\\sqrt{\\sum_{p\\in P} r^2_{b,p}}}$$\n",
    "    <br>\n",
    "</ul>\n",
    "\n",
    "  \n",
    "<br>\n",
    "where: \n",
    "\n",
    "* $a$ and $b$ are users\n",
    "* $P$ is the set of items that both users $a$ and $b$ have ever rated.\n",
    "* $r_{a,p}$ is the rating of item $p$ by user $a$\n",
    "* $\\bar{r_a}$ is the mean rating given by user $a$\n",
    "\n",
    "\n",
    "So, let us implement this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance-based similarity: 0.07263669959755374\n",
      "Pearson correlation-based similarity: 0.06317948789567646\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# euclidean distance based similarity using scipy's euclidean definition\n",
    "def euclideanSimilarity(v1, v2):\n",
    "    return 1.0 / (1.0 + euclidean(v1,v2))\n",
    "\n",
    "# wrapper for pearson correlation similarity which uses scipy's definition\n",
    "def pearsonSimilarity(v1, v2):\n",
    "    res = pearsonr(v1, v2)[0]\n",
    "    if math.isnan(res) or res < 0:\n",
    "        res = 0\n",
    "    return res\n",
    "\n",
    "# Returns a similarity score for two users\n",
    "def similarityFunction(myData, user1, user2, similarity=euclideanSimilarity):\n",
    "    # Get movies rated by user1\n",
    "    movies_user1 = myData[myData['user_id'] == user1]\n",
    "    # Get movies rated by user2\n",
    "    movies_user2 = myData[myData['user_id'] == user2]\n",
    "    \n",
    "    # Find commonly rated films\n",
    "    rep=pd.merge(movies_user1, movies_user2, on='movie_id')    \n",
    "\n",
    "    return similarity(rep['rating_x'], rep['rating_y'])\n",
    "\n",
    "\n",
    "print(\"Euclidean distance-based similarity:\", similarityFunction(data, \n",
    "                                                                 data.user_id.unique()[10], \n",
    "                                                                 data.user_id.unique()[11]))\n",
    "\n",
    "print(\"Pearson correlation-based similarity:\", similarityFunction(data, \n",
    "                                                                  data.user_id.unique()[10], \n",
    "                                                                  data.user_id.unique()[11], \n",
    "                                                                  similarity=pearsonSimilarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Question #1.-<br>\n",
    "<span style=\"color:black\">Implement the cosine similarity\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Following Cosine equation we obtain: 0.9406954990098857 \n",
      " and using library we obtain:0.9406954990098856 \n",
      "Cosine similarity: (0.9406954990098857, 0.9406954990098856)\n"
     ]
    }
   ],
   "source": [
    "# Question 1\n",
    "from scipy import spatial\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "# cosine similarity\n",
    "def cosineSimilarity(v1, v2):\n",
    "    # Following the equation\n",
    "    cos1 = dot(v1,v2)/(norm(v1)*norm(v2))\n",
    "    # Using library spatial from scipy\n",
    "    cos2 = 1.0 - spatial.distance.cosine(v1,v2)\n",
    "    print(f'Following Cosine equation we obtain: {cos1} \\n and using library we obtain:{cos2} ')\n",
    "    return cos1, cos2\n",
    "    \n",
    "print(\"Cosine similarity:\", similarityFunction(data,\n",
    "                                               data.user_id.unique()[10], \n",
    "                                               data.user_id.unique()[11], \n",
    "                                               similarity=cosineSimilarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues to take into accout\n",
    "<ul>\n",
    "<li>Pearson Correlation is usually preferred over euclidean distance, since it uses the ranking and disregards the specific ratings.</li>\n",
    "<li>Cosine distance is usually preferred when our data is binary/unary; i.e., [like vs. unlike] or [buy vs. not-buy].</li>\n",
    "<li>In general, these definitions of similarity suffer when two users have very few items in common.</li>\n",
    "</ul>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #2.-<br>\n",
    "<span style=\"color:black\">Modify the previous similarity function so that it only measures the similarity between two users if the number of movies that both users have seen is equal or larger than a given threshold (parameter `minCommonItems`).\n",
    "    <br />\n",
    "    Otherwise, return 0.\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean similarity: 0.07263669959755374\n",
      "Pearson similarity: 0.06317948789567646\n",
      "Cosine similarity: 0.9406954990098857\n"
     ]
    }
   ],
   "source": [
    "def cosineSimilarity1(v1, v2):\n",
    "    # Following the equation\n",
    "    cos = dot(v1,v2)/(norm(v1)*norm(v2))\n",
    "    return cos\n",
    "\n",
    "# Question 2\n",
    "\n",
    "# Returns a similarity score for two users\n",
    "def similarityFunction2(myData, user1, user2, similarity=euclideanSimilarity, minCommonItems=300):\n",
    "    #We can see that for this example both users have 300 items in commoon\n",
    "    \n",
    "    #Get movies rated by user 1\n",
    "    movies_user1 = myData[myData['user_id'] == user1]\n",
    "    #Get movies rated by user 2\n",
    "    movies_user2 = myData[myData['user_id'] == user2]\n",
    "\n",
    "    #Measure the similarity if the number of movies that both users have seen is equal\n",
    "    if movies_user1.movie_id.count() & movies_user2.movie_id.count()>=minCommonItems:\n",
    "        rep = pd.merge(movies_user1,movies_user2, on = 'movie_id')\n",
    "        return similarity(rep['rating_x'], rep['rating_y'])\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "print(\"Euclidean similarity:\", similarityFunction2(data,\n",
    "                                               data.user_id.unique()[10], \n",
    "                                               data.user_id.unique()[11], \n",
    "                                               similarity=euclideanSimilarity))    \n",
    "print(\"Pearson similarity:\", similarityFunction2(data,\n",
    "                                               data.user_id.unique()[10], \n",
    "                                               data.user_id.unique()[11], \n",
    "                                               similarity=pearsonSimilarity))  \n",
    "print(\"Cosine similarity:\", similarityFunction2(data,\n",
    "                                               data.user_id.unique()[10], \n",
    "                                               data.user_id.unique()[11], \n",
    "                                               similarity=cosineSimilarity1))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we already have a similarity function between users. But many others could be used instead.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #3.-<br>\n",
    "<span style=\"color:black\">Create a new similarity function that deals with small $P$ sets differently: we are going to weigh the similarity (previous definition) by the relative size of $P$ over $50$ items...\n",
    "$$sim\\_alt(a,b) = sim(a,b) * \\frac{min(100,|P_{ab}|)}{100} $$\n",
    "where $|P_{ab}|$ is the number of common items for users $a$ and $b$.\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean distance-based similarity: 0.05738299268206746\n",
      "Pearson correlation-based similarity: 0.0499117954375844\n",
      "Cosine similarity: 0.7431494442178097\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Returns a weighted similarity score for two users\n",
    "def weightedSimilarityFunction(myData, user1, user2, similarity=euclideanSimilarity):\n",
    "    #Get movies rated by user 1\n",
    "    movies_user1 = myData[myData['user_id'] == user1]\n",
    "    #Get movies rated by user 2\n",
    "    movies_user2 = myData[myData['user_id'] == user2]\n",
    "    \n",
    "    # We are going to weigh the Similarity by the relative size of P over 50 items\n",
    "    rep = pd.merge(movies_user1,movies_user2, on = 'movie_id')\n",
    "    P = len(rep)  # Numbner of common movies\n",
    "    WeightSimilarity = float(min(100,P)/100.0)\n",
    "    \n",
    "    sim = similarity(rep['rating_x'], rep['rating_y'])* WeightSimilarity\n",
    "\n",
    "    return sim\n",
    "    \n",
    "    \n",
    "print(\"Euclidean distance-based similarity:\", weightedSimilarityFunction(data, \n",
    "                                                                         data.user_id.unique()[10], \n",
    "                                                                         data.user_id.unique()[11]))\n",
    "\n",
    "print(\"Pearson correlation-based similarity:\", weightedSimilarityFunction(data, \n",
    "                                                                          data.user_id.unique()[10], \n",
    "                                                                          data.user_id.unique()[11], \n",
    "                                                                          similarity=pearsonSimilarity))\n",
    "\n",
    "print(\"Cosine similarity:\", weightedSimilarityFunction(data,\n",
    "                                                       data.user_id.unique()[10], \n",
    "                                                       data.user_id.unique()[11], \n",
    "                                                       similarity=cosineSimilarity1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, we have defined how to measure similarity between users. Now, how can we use this information to make recommendations?\n",
    "\n",
    "## How do we generate recommendations from others' ratings?\n",
    "\n",
    "We might reformulate this problem as: can we *estimate* the rating that a user $a$ would give to an item $p$?\n",
    "Then, we would need to recommend to the user those items with the highest estimated rating.\n",
    "\n",
    "We can estimate the rating $\\hat{r}_{a,p}$ given by user $a$ to item $p$ as a weighted average of other users' ratings for item $p$ weighted by their similarity with user $a$:\n",
    "\n",
    "$$\\hat{r}_{a,p}= \\frac{\\sum_{b \\in N}{sim(a,b) \\cdot r_{b,p}}}{\\sum_{b \\in N}{sim(a,b)}}$$\n",
    "\n",
    "where $N$ is the set of users that have rated item $p$.\n",
    "<br><br>\n",
    "\n",
    "### Example:\n",
    "<br>\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td>User</td>\n",
    "    <td>$sim(a,b)$</td> \n",
    "    <td>$r_{b,p_1}$ for item $p_1$</td>\n",
    "    <td>$r_{b,p_2}$ for item $p_2$</td>\n",
    "    <td>$sim(a,b)\\cdot r_{b,p_1}$</td>\n",
    "    <td>$sim(a,b)\\cdot r_{b,p_2}$</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b1</td>\n",
    "    <td>0.99</td> \n",
    "    <td>3</td>\n",
    "    <td>2.5</td>\n",
    "    <td>2.97</td>\n",
    "    <td>2.48</td>\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b2</td>\n",
    "    <td>0.38</td> \n",
    "    <td>3</td>\n",
    "    <td>3</td>\n",
    "    <td>1.14</td>\n",
    "    <td>1.14</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b3</td>\n",
    "    <td>0.89</td>\n",
    "    <td>4.5</td>\n",
    "    <td> - </td>\n",
    "    <td>4.0</td>\n",
    "    <td> - </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b4</td>\n",
    "    <td>0.92</td>\n",
    "    <td>3</td>\n",
    "    <td>3</td>\n",
    "    <td>2.76</td>\n",
    "    <td>2.76</td>\n",
    "  </tr>\n",
    "  <tr style=\"border-top:1px solid black\">\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b) \\cdot r_{b,p}}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>10.87</td>\n",
    "    <td>6.38</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>3.18</td>\n",
    "    <td>2.29</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>$pred(a,p)$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>3.42</td>\n",
    "    <td>2.78</td>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put these ideas into practice. We want to estimate the rating that user `u` would give to movie `m`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: user 7 has already rated movie 300  with value: 4.0\n",
      "The estimated rating for user 7 and movie 300 is: 3.693789893715973\n"
     ]
    }
   ],
   "source": [
    "u = 7\n",
    "m = 300\n",
    "\n",
    "# Let's find other users' ratings for movie m\n",
    "ratings_for_m = data[data['movie_id'] == m]\n",
    "\n",
    "sim_with_u = {}\n",
    "users_rated_m = list(ratings_for_m['user_id'])\n",
    "\n",
    "# Let's reduce the size of the dataset: we only are interested in all the ratings for movies also rated by u\n",
    "mrbu = data[data['user_id'] == u][['movie_id']] # movies rated by u\n",
    "data_u = pd.merge(data, mrbu, on='movie_id')      # all the ratings for movies rated by u\n",
    "\n",
    "num = 0\n",
    "den = 0\n",
    "for ous in users_rated_m:\n",
    "    if ous == u: \n",
    "        print(\"Warning: user\", u, \"has already rated movie\", m,\" with value:\", \n",
    "             float(ratings_for_m.rating[ratings_for_m['user_id'] == u]))\n",
    "        continue \n",
    "\n",
    "    sim = similarityFunction(data_u, u, ous) # calculate similarity\n",
    "    num += sim * float(ratings_for_m.rating[ratings_for_m['user_id']==ous])\n",
    "    den += sim\n",
    "\n",
    "print(\"The estimated rating for user\",u,\"and movie\",m,\"is:\", num/den)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of `u` and set it to '7' and see what happens.\n",
    "\n",
    "But, we need to do all this in a general way considering any possible pair (user,movie) and thus measuring similarity between all pairs of users.\n",
    "\n",
    "Let's build a class that learns from a dataset (creates a similarity matrix for users) and then provides rating estimations for any given pair (user,movie).\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #4.-<br>\n",
    "<span style=\"color:black\">Implement the previous calculations in a general recommender system class. To do so, complete the 5 following TODO's.\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "class CollaborativeFiltering:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity=similarityFunction):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_metric = similarity \n",
    "        self.df = None\n",
    "        self.sim =  euclideanSimilarity # similary matrix for users (diagonal symmetric)\n",
    "\n",
    "    def getSimilarityMatrix(self):\n",
    "        return copy.deepcopy(self.sim)\n",
    "\n",
    "    def setSimilarityMatrix(self, sim):\n",
    "        self.sim = sim\n",
    "        \n",
    "    def fit(self, myData):\n",
    "        \"\"\" Prepare data structures for estimation. Compute a similarity matrix among users \"\"\"\n",
    "        self.df = myData\n",
    "        if self.sim is None:\n",
    "            allUsers = list(self.df['user_id'].unique())\n",
    "            self.sim = {key: {} for key in allUsers}\n",
    "\n",
    "            for p1id in np.arange(len(allUsers)-1):\n",
    "                user1 = allUsers[p1id]\n",
    "                mrbp1 = self.df[self.df['user_id']==user1][['movie_id']]#### TODO 4.1: store in this variable all the 'movie_id' of all movies rated by p1\n",
    "                data_p1 = pd.merge(self.df, mrbp1, on='movie_id')          # all the ratings for movies rated by p1\n",
    "                for p2id in np.arange(p1id+1, len(allUsers)):\n",
    "                    user2 = allUsers[p2id]\n",
    "                    sim = self.sim_metric(data_p1,user1,user2)#### TODO 4.2: call the appropriate function to calculate the similarity\n",
    "                    self.sim[user1][user2] = sim\n",
    "                    self.sim[user2][user1] = sim\n",
    "                \n",
    "    def predict(self, user_id, movie_id):\n",
    "        \"\"\" Estimate the rating that 'user_id' would give to 'movie_id' \"\"\"\n",
    "        rating_num = 0.0\n",
    "        rating_den = 0.0\n",
    "        #### TODO 4.3: is user_id known? it should be in the similarity matrix, if so\n",
    "        if len(self.df[self.df['user_id'] == user_id]) > 0:\n",
    "            user_exists_in_mat=True \n",
    "        else:\n",
    "            user_exists_in_mat=False\n",
    "        \n",
    "        #user_exists_in_mat = user_id in self.sim\n",
    "        df_ratings_for_movie = self.df[self.df['movie_id'] == movie_id] # all the ratings for movie_id\n",
    "        if user_exists_in_mat: \n",
    "            allUsers = set(df_ratings_for_movie['user_id']) # all the users that have ever rated movie_id\n",
    "            for other_user in allUsers:\n",
    "                if user_id == other_user: \n",
    "                    print(\"Warning: user\", user_id, \"has already rated movie\", movie_id,\" with value:\", \n",
    "                          float(df_ratings_for_movie.rating[df_ratings_for_movie['user_id'] == user_id]))\n",
    "                    continue \n",
    "                \n",
    "                #rating_num += #### TODO 4.4: calculate and add to this variable the addition to the numerator\n",
    "                              #              relative to the current other user \n",
    "                rating_num += self.sim(user_id, other_user) * float(df_ratings_for_movie.rating[df_ratings_for_movie['user_id'] == other_user])\n",
    "                #rating_den += #### TODO 4.5: calculate and add to this variable the addition to the denominator\n",
    "                              #              relative to the current other user\n",
    "                rating_den += self.sim(user_id, other_user)\n",
    "\n",
    "        if rating_den == 0: # if we couldn't make a regular estimation:\n",
    "            if df_ratings_for_movie.rating.mean() > 0:\n",
    "                # return the unweighted mean movie rating if there are ratings available for movie_id\n",
    "                return df_ratings_for_movie.rating.mean()\n",
    "            elif user_exists_in_mat:\n",
    "                # or return the mean user rating if there is no previous rating for that movie\n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "            else:\n",
    "                # or return a constant value (mid-scale rating) if no information at all is available\n",
    "                return 3;\n",
    "\n",
    "        return rating_num/rating_den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's test this CF class!\n",
    "\n",
    "First of all, we learn the similarity matrix (this might take a while!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recsys = CollaborativeFiltering()\n",
    "my_recsys.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, now, we can estimate the rating that user 'user_id' would give to movie 'movie_id':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated rating for user 1 and movie 300 is: 3.5975182755080346\n"
     ]
    }
   ],
   "source": [
    "u=1\n",
    "m=300\n",
    "est_rating = my_recsys.predict(user_id=u, movie_id=m) # Estimate the rating that user 'u' would give to movie 'm'\n",
    "print(\"The estimated rating for user\",u,\"and movie\",m,\"is:\", est_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Can the previous predictive function be improved?\n",
    "\n",
    "### 1) Normalization: Predictions scaled to the user domain\n",
    "\n",
    "Users tend to rate differently: some users' average is high, others' is low. We can try to adapt to our prediction to the user's mean:<br>\n",
    "\n",
    "$$\\hat{r}^N_{a,p} = \\bar{r_a} + \\frac{\\sum_{b \\in N}{sim(a,b)\\cdot (r_{b,p}-\\bar{r_b})}}{\\sum_{b \\in N}{sim(a,b)}}$$\n",
    "\n",
    "\n",
    "where $\\bar{r_b}$ is the mean rating of user $b$.<br>\n",
    "\n",
    "\n",
    "This prediction function was used in the original Netflix system.\n",
    "\n",
    "<br><br>\n",
    "### Example:\n",
    "Prediction for user $a$ with mean rating $\\bar{r_a} = 3.5$\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <td>User</td>\n",
    "    <td>$sim(a,b)$</td> \n",
    "    <td>Mean rating: $\\bar{r_b}$</td>\n",
    "    <td>$r_{b,p_1}$ for item $p_1$</td>\n",
    "    <td>$sim(a,b)*(r_{b,p_1}-\\bar{r_b})$</td>\n",
    "\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b1</td>\n",
    "    <td>0.99</td> \n",
    "    <td>4.3</td> \n",
    "    <td>3</td>\n",
    "    <td>-1.29</td>\n",
    "\n",
    "    \n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b2</td>\n",
    "    <td>0.38</td> \n",
    "    <td>2.73</td> \n",
    "    <td>3</td>\n",
    "    <td>0.10</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b3</td>\n",
    "    <td>0.89</td>\n",
    "    <td>3.12</td>  \n",
    "    <td>4.5</td>\n",
    "    <td>1.23</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>b4</td>\n",
    "    <td>0.92</td>\n",
    "    <td>3.98</td>  \n",
    "    <td>3</td>\n",
    "    <td>-0.90</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr style=\"border-top:1px solid black\">\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)\\cdot (r_{b,p}-\\bar{r_b})}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>-0.86</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>$\\sum_{b \\in N}{sim(a,b)}$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>3.18</td>\n",
    "\n",
    "  </tr>\n",
    "  <tr>\n",
    "  <td>$pred(a,p)$</td>\n",
    "    <td></td> \n",
    "    <td></td>\n",
    "    <td></td>\n",
    "    <td>3.23</td>\n",
    "\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Question #5.-<br>\n",
    "<span style=\"color:black\">Create a new CF RecSys that uses normalization in the predictions. Name it `NormalizedCollaborativeFiltering`<br/>\n",
    "    \n",
    "    Tip: Copy the structure of the previous class, `CollaborativeFiltering`. Use an attribute `mean_ratings` to store the mean value given by each user, and estimate it during fitting. Consider the mean ratings as explained above during the prediction.\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "class NormalizedCollaborativeFiltering:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u') normalized by user's mean rating. \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity=similarityFunction):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_metric = similarity\n",
    "        self.df = None\n",
    "        self.sim = None # similary matrix for users (diagonal symmetric)\n",
    "        self.mean_ratings = None # users' mean ratings\n",
    "\n",
    "    #### TODO: work here. Copy from previous implementation, first; add new functionalities latter on.\n",
    "\n",
    "    def predict(self, user_id, movie_id):\n",
    "        \"\"\" Estimate the rating that 'user_id' would give to 'movie_id' \"\"\"\n",
    "        rating_num = 0.0\n",
    "        rating_den = 0.0\n",
    "        #### TODO 4.3: is user_id known? it should be in the similarity matrix, if so\n",
    "        if len(self.df[self.df['user_id'] == user_id]) > 0:\n",
    "            user_exists_in_mat=True \n",
    "        else:\n",
    "            user_exists_in_mat=False\n",
    "\n",
    "        #user_exists_in_mat = user_id in self.sim\n",
    "        df_ratings_for_movie = self.df[self.df['movie_id'] == movie_id] # all the ratings for movie_id\n",
    "        if user_exists_in_mat: \n",
    "            allUsers = set(df_ratings_for_movie['user_id']) # all the users that have ever rated movie_id\n",
    "            for other_user in allUsers:\n",
    "                if user_id == other_user: \n",
    "                    print(\"Warning: user\", user_id, \"has already rated movie\", movie_id,\" with value:\", \n",
    "                          float(df_ratings_for_movie.rating[df_ratings_for_movie['user_id'] == user_id]))\n",
    "                    continue \n",
    "\n",
    "                #rating_num += #### TODO 4.4: calculate and add to this variable the addition to the numerator\n",
    "                              #              relative to the current other user \n",
    "                rating_num += self.sim(user_id, other_user) * float(df_ratings_for_movie.rating[df_ratings_for_movie['user_id'] == other_user])\n",
    "                #rating_den += #### TODO 4.5: calculate and add to this variable the addition to the denominator\n",
    "                              #              relative to the current other user\n",
    "                rating_den += self.sim(user_id, other_user)\n",
    "\n",
    "        if rating_den == 0: # if we couldn't make a regular estimation:\n",
    "            if df_ratings_for_movie.rating.mean() > 0:\n",
    "                # return the unweighted mean movie rating if there are ratings available for movie_id\n",
    "                return df_ratings_for_movie.rating.mean()\n",
    "            elif user_exists_in_mat:\n",
    "                # or return the mean user rating if there is no previous rating for that movie\n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "            else:\n",
    "                # or return a constant value (mid-scale rating) if no information at all is available\n",
    "                return 3;\n",
    "\n",
    "        return rating_num/rating_den\n",
    " \n",
    "    \n",
    "    def fit(self, myData):\n",
    "        \"\"\" Prepare data structures for estimation. \"\"\"\n",
    "        self.df = myData\n",
    "        if self.sim is None:\n",
    "            self.createSimMatrix()\n",
    "        if self.mean_ratings is None:\n",
    "            self.calculateMeanRatings()\n",
    "        \n",
    "    def createSimMatrix(self):\n",
    "        \"\"\" Compute a similarity matrix among users \"\"\"\n",
    "        self.df = myData\n",
    "        if self.sim is None:\n",
    "            allUsers = list(self.df['user_id'].unique())\n",
    "            self.sim = {key: {} for key in allUsers}\n",
    "\n",
    "            for p1id in np.arange(len(allUsers)-1):\n",
    "                user1 = allUsers[p1id]\n",
    "                mrbp1 = self.df[self.df['user_id']==user1][['movie_id']]#### TODO 4.1: store in this variable all the 'movie_id' of all movies rated by p1\n",
    "                data_p1 = pd.merge(self.df, mrbp1, on='movie_id')          # all the ratings for movies rated by p1\n",
    "                for p2id in np.arange(p1id+1, len(allUsers)):\n",
    "                    user2 = allUsers[p2id]\n",
    "                    sim = self.sim_metric(data_p1,user1,user2)#### TODO 4.2: call the appropriate function to calculate the similarity\n",
    "                    self.sim[user1][user2] = sim\n",
    "                    self.sim[user2][user1] = sim\n",
    "\n",
    "    def calculateMeanRatings(self):\n",
    "        print(\"calculate_mean_ratings: not implemented yet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this new CF class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_norm_recsys = NormalizedCollaborativeFiltering()\n",
    "my_norm_recsys.setSimilarityMatrix(my_recsys.getSimilarityMatrix()) # to save time, let's reuse the sim matrix\n",
    "my_norm_recsys.fit(data) # thus, this only will calculate the mean rating of the users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, now, we can estimate the rating that user `u` would give to movie `m` with this new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=1\n",
    "m=300\n",
    "est_rating = my_norm_recsys.predict(user_id=u, movie_id=m) # Estimate the rating that user 'u' would give to movie 'm'\n",
    "print(\"The estimated rating for user\",u,\"and movie\",m,\"is:\", est_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2) Not all the neighbor ratings might be equal\n",
    "Agreement on commonly liked items is not as important as agreement on controversial items. We could weigh user similarity according to the rating variance.\n",
    "\n",
    "### 3) Value of number of co-rated items\n",
    "Reduce the similarity between users when the number of co-rated items is low or discard those users with a small number of co-rated items.\n",
    "\n",
    "### 4) Case amplification\n",
    "Increase the weigth to those users which are really really similar to each other (~= 1).\n",
    "\n",
    "### 5) Neighborhood selection\n",
    "Only a subset of similar users are used to make recommendations. Dissimilar users are discarded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Question #6.-<br>\n",
    "<span style=\"color:black\">Create a new RecSys that estimates the score of movie `movie_id` as given by user `user_id` only using the subset of the `N` most similar users to `user_id`. \n",
    "\n",
    "    Tip: Copy the structure of the first class, `CollaborativeFiltering`. Use an attribute `N` to store the no. of most similar users to consider. Create a function that returns the N most similar users for a given `user_id`. Consider only these most similar users to make the prediction.\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "    \n",
    "class NNCollaborativeFiltering:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u') and considering only the most similar N users \"\"\"\n",
    "    \n",
    "    def __init__(self, N=10, similarity=similarityFunction):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_metric = similarity\n",
    "        self.N = N\n",
    "        self.df = None\n",
    "        self.sim = None # similary matrix for users (diagonal symmetric)\n",
    "\n",
    "    def getSimilarityMatrix(self):\n",
    "        return copy.deepcopy(self.sim)\n",
    "\n",
    "    def setSimilarityMatrix(self, sim):\n",
    "        self.sim = sim\n",
    "\n",
    "    #### TODO: work here. Copy from previous implementation, first; add new functionalities latter on.\n",
    "\n",
    "    def get_N_most_similar_users(self, user_id):\n",
    "        print(\"get_N_most_similar_users: not implemented yet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this new CF class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_nn_recsys = NNCollaborativeFiltering()\n",
    "my_nn_recsys.setSimilarityMatrix(my_recsys.getSimilarityMatrix()) # to save time, let's reuse the sim matrix\n",
    "my_nn_recsys.fit(data) # thus, this only will set the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, now, we can estimate the rating that user `u` would give to movie `m` with this new function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=1\n",
    "m=300\n",
    "est_rating = my_nn_recsys.predict(user_id=u, movie_id=m) # Estimate the rating that user 'u' would give to movie 'm'\n",
    "print(\"The estimated rating for user\",u,\"and movie\",m,\"is:\", est_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
