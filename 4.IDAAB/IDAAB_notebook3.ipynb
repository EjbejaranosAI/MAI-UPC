{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems\n",
    "\n",
    "<small><i>Updated January 2022</i></small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\" style = \"border-radius:10px;border-width:3px;border-color:darkblue;font-family:Verdana,sans-serif;font-size:16px;\">\n",
    "<h2>Outline</h2>\n",
    "<ol>\n",
    "    <li>What is a recommender system?</li>\n",
    "    <li>How to build a recommender system? </li>\n",
    "    <li>How to evaluate its success?</li>\n",
    "</ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps to build a recommender system:\n",
    "<ol>\n",
    "    <li>Data collection and understanding</li>\n",
    "    <li>Data filtering/cleaning</li>\n",
    "    <li>Learning<br>\n",
    "        <span style=\"font-size:smaller\">E.g., using item/user similarity function</span></li>\n",
    "    <li>Evaluation</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr/>\n",
    "\n",
    "# Hands on\n",
    "## Evaluating a RecSys: case use on our CF RecSys for Movielens\n",
    "\n",
    "We will use again the MovieLens dataset, which you should have downloaded to complete the first notebook.\n",
    "\n",
    "Let us first load the libraries that we are going to need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(150000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 150 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 150\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "import random\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, next, the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The dataset is composed of 3 main files\n",
    "\n",
    "# The users file \n",
    "u_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\n",
    "users = pd.read_csv('ml-100k/u.user', sep='|', names=u_cols)\n",
    "\n",
    "# The movies (items) file\n",
    "m_cols = ['movie_id', 'title', 'release_date']\n",
    "# It contains aditional columns indicating, among other the movies' genre.\n",
    "# Let's only load the first three columns:\n",
    "movies = pd.read_csv('ml-100k/u.item', sep='|', names=m_cols, usecols=range(3), encoding='latin-1')\n",
    "\n",
    "# The ratings file \n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=r_cols)\n",
    "\n",
    "\n",
    "# We merge all three dataframes into a single dataset\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "# and keep only the columns that we are going to use\n",
    "data = data[['user_id', 'rating', 'movie_id', 'title']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a subset of just 100 users, the ones with a largest number of ratings. We keep a 20% of them for evaluation purposes, and learn with the remaining 80%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: (11019, 4)\n",
      "Usuaris: 100\n",
      "Films: 1238\n",
      "The training set has 8790 ratings, and the test set 2229\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(7) # for replicability\n",
    "\n",
    "# We keep only data regarding the 100 users with the largest number of ratings\n",
    "#user_id_most_raters = data.groupby('user_id').size().sort_values(ascending=False).head(100).keys()\n",
    "#data = data[data['user_id'].isin(user_id_most_raters)].copy()\n",
    "data = data[data['user_id']<=100].copy() # get only data from 100 users\n",
    "print('Dataset size:', data.shape)\n",
    "print('Usuaris:', data.user_id.nunique())\n",
    "print('Films:',data.movie_id.nunique())\n",
    "\n",
    "# Make train/test partition\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "trData = data[msk]\n",
    "tsData = data[~msk]\n",
    "\n",
    "print(\"The training set has \"+ str(trData.shape[0]) +\" ratings, and the test set \"+ str(tsData.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the similarity function defined in the second noteboook. By default, we use Pearson Similarity and a lower bound of 5 minimum items rated in common to measure it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# euclidean distance based similarity using scipy's euclidean definition\n",
    "def euclideanSimilarity(v1, v2):\n",
    "    return 1.0 / (1.0 + euclidean(v1,v2))\n",
    "\n",
    "# wrapper for pearson correlation similarity which uses scipy's definition\n",
    "def pearsonSimilarity(v1, v2):\n",
    "    res = pearsonr(v1, v2)[0]\n",
    "    if math.isnan(res) or res < 0:\n",
    "        res = 0\n",
    "    return res\n",
    "\n",
    "# Returns a similarity score for two users\n",
    "def similarityFunction(myData, user1, user2, similarity=pearsonSimilarity, minCommonItems=5):\n",
    "    # Get movies rated by user1\n",
    "    movies_user1 = myData[myData['user_id'] == user1]\n",
    "    # Get movies rated by user2\n",
    "    movies_user2 = myData[myData['user_id'] == user2]\n",
    "    \n",
    "    # Find commonly rated films\n",
    "    rep = pd.merge(movies_user1, movies_user2, on='movie_id')    \n",
    "    if len(rep) < minCommonItems:\n",
    "        return 0   \n",
    "\n",
    "    return similarity(rep['rating_x'], rep['rating_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Copy** in the following cell you implementation of the CF class that you implemented in the second notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### TODO: copy here your implementation of CollaborativeFiltering class from Notebook 2\n",
    "class CollaborativeFiltering:\n",
    "    \"\"\" Collaborative filtering using a custom sim(u,u'). \"\"\"\n",
    "    \n",
    "    def __init__(self, similarity=similarityFunction):\n",
    "        \"\"\" Constructor \"\"\"\n",
    "        self.sim_metric = similarity \n",
    "        self.df = None\n",
    "        self.sim =  euclideanSimilarity # similary matrix for users (diagonal symmetric)\n",
    "\n",
    "    def getSimilarityMatrix(self):\n",
    "        return copy.deepcopy(self.sim)\n",
    "\n",
    "    def setSimilarityMatrix(self, sim):\n",
    "        self.sim = sim\n",
    "        \n",
    "    def fit(self, myData):\n",
    "        \"\"\" Prepare data structures for estimation. Compute a similarity matrix among users \"\"\"\n",
    "        self.df = myData\n",
    "        if self.sim is None:\n",
    "            allUsers = list(self.df['user_id'].unique())\n",
    "            self.sim = {key: {} for key in allUsers}\n",
    "\n",
    "            for p1id in np.arange(len(allUsers)-1):\n",
    "                user1 = allUsers[p1id]\n",
    "                mrbp1 = self.df[self.df['user_id']==user1][['movie_id']]#### TODO 4.1: store in this variable all the 'movie_id' of all movies rated by p1\n",
    "                data_p1 = pd.merge(self.df, mrbp1, on='movie_id')          # all the ratings for movies rated by p1\n",
    "                for p2id in np.arange(p1id+1, len(allUsers)):\n",
    "                    user2 = allUsers[p2id]\n",
    "                    sim = self.sim_metric(data_p1,user1,user2)#### TODO 4.2: call the appropriate function to calculate the similarity\n",
    "                    self.sim[user1][user2] = sim\n",
    "                    self.sim[user2][user1] = sim\n",
    "                \n",
    "    def predict(self, user_id, movie_id):\n",
    "        \"\"\" Estimate the rating that 'user_id' would give to 'movie_id' \"\"\"\n",
    "        rating_num = 0.0\n",
    "        rating_den = 0.0\n",
    "        #### TODO 4.3: is user_id known? it should be in the similarity matrix, if so\n",
    "        if len(self.df[self.df['user_id'] == user_id]) > 0:\n",
    "            user_exists_in_mat=True \n",
    "        else:\n",
    "            user_exists_in_mat=False\n",
    "        \n",
    "        #user_exists_in_mat = user_id in self.sim\n",
    "        df_ratings_for_movie = self.df[self.df['movie_id'] == movie_id] # all the ratings for movie_id\n",
    "        if user_exists_in_mat: \n",
    "            allUsers = set(df_ratings_for_movie['user_id']) # all the users that have ever rated movie_id\n",
    "            for other_user in allUsers:\n",
    "                if user_id == other_user: \n",
    "                    print(\"Warning: user\", user_id, \"has already rated movie\", movie_id,\" with value:\", \n",
    "                          float(df_ratings_for_movie.rating[df_ratings_for_movie['user_id'] == user_id]))\n",
    "                    continue \n",
    "                \n",
    "                #rating_num += #### TODO 4.4: calculate and add to this variable the addition to the numerator\n",
    "                              #              relative to the current other user \n",
    "                rating_num += self.sim(user_id, other_user) * float(df_ratings_for_movie.rating[df_ratings_for_movie['user_id'] == other_user])\n",
    "                #rating_den += #### TODO 4.5: calculate and add to this variable the addition to the denominator\n",
    "                              #              relative to the current other user\n",
    "                rating_den += self.sim(user_id, other_user)\n",
    "\n",
    "        if rating_den == 0: # if we couldn't make a regular estimation:\n",
    "            if df_ratings_for_movie.rating.mean() > 0:\n",
    "                # return the unweighted mean movie rating if there are ratings available for movie_id\n",
    "                return df_ratings_for_movie.rating.mean()\n",
    "            elif user_exists_in_mat:\n",
    "                # or return the mean user rating if there is no previous rating for that movie\n",
    "                return self.df.rating[self.df['user_id']==user_id].mean()\n",
    "            else:\n",
    "                # or return a constant value (mid-scale rating) if no information at all is available\n",
    "                return 3;\n",
    "\n",
    "        return rating_num/rating_den"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we train it with the training subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_recsys = CollaborativeFiltering()\n",
    "my_recsys.fit(trData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are interested in defining how we are going to evaluate the recommender systems that we build.\n",
    "\n",
    "## Evaluation criteria: metrics\n",
    "\n",
    "Performance evaluation of recommender systems is itself an entire research topic. Some commonly used metrics include:<br>\n",
    "* $RMSE = \\sqrt{(\\frac{\\sum(\\hat{y}-y)^2}{n})}$\n",
    "* Precision / Recall / F-scores\n",
    "* ROC curves\n",
    "* Cost curves\n",
    "\n",
    "Let's implement the root mean square error (RMSE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_pred, y_true):\n",
    "    \"\"\" Compute Root Mean Squared Error. \"\"\"\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def evaluate(estimation_func, myTsData, metric=rmse):\n",
    "    \"\"\" RMSE-based predictive performance evaluation with pandas. \"\"\"\n",
    "    \n",
    "    # we keep the pairs user-movie for which we are going to obtain an estimation\n",
    "    pairs_to_estimate = zip(myTsData.user_id, myTsData.movie_id)\n",
    "\n",
    "    # we do obtain the estimations\n",
    "    estimated_values = np.array([estimation_func(u,i) for (u,i) in pairs_to_estimate ])\n",
    "\n",
    "    # finally, we compare the estimations and the real values with the chosen metric\n",
    "    real_values = myTsData.rating.values\n",
    "    return metric(estimated_values, real_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we calculate the RMSE of this estimation procedure within the test data (this might take a while!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Collaborative Recommender: 1.0913862892104704\n"
     ]
    }
   ],
   "source": [
    "print('RMSE for Collaborative Recommender: %s' % evaluate(my_recsys.predict, tsData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, we obtain a performance measure for our RecSys that we can use for evaluation or model selection. In this context, RMSE and MAE (mean absolute error) are the most popular metrics. \n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #1.-<br>\n",
    "<span style=\"color:black\">Implement MAE.\n",
    "</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "\n",
    "\n",
    "def mae(y_pred, y_true):\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(y_true)):\n",
    "        sum_error += abs(y_true[i]- y_pred[i])\n",
    "    print(f\"mae is : {sum_error}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae is : 1915.5492456394904\n",
      "MAE for Collaborative Recommender: None\n"
     ]
    }
   ],
   "source": [
    "print('MAE for Collaborative Recommender: %s' % evaluate(my_recsys.predict, tsData, metric=mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the main criticism of these metrics is that they really don't measure user experience. \n",
    "As users are commonly presented with a set of `N` recommendations for they to choose from, evaluating according to the top-N recommendations is probably closer to what is important to the final user.\n",
    "<br>\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #2.-<br>\n",
    "<span style=\"color:black\">Create a new method in the recommender class that returns the top-N recommendations for a user, where N is a parameter of the method. Recommendations need to be movies unseen by the user.</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2\n",
    "import operator\n",
    "\n",
    "def get_top_N_recommendations(self, user_id, N=10):\n",
    "    print(\"get_top_N_recommendations: not implemented yet\")\n",
    "\n",
    "\n",
    "# We add this function to the CF class: it returns the N items with largest \n",
    "# estimated rating as recommendations\n",
    "CollaborativeFiltering.get_top_N_recommendations = get_top_N_recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, now, we can obtain the set of movies recommended to user 'user_id':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_top_N_recommendations: not implemented yet\n"
     ]
    }
   ],
   "source": [
    "my_recsys.get_top_N_recommendations(user_id=1,N=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we evaluate this type of recommendation? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Average Precision at N\n",
    "In machine learning, we define precision as:\n",
    "$$ P=\\frac{TP}{FP+TP}$$\n",
    "that is, the proportion of really relevant items among all the recommended items.\n",
    "\n",
    "Precision at K is defined as the precision calculated by considering only the first K recommendations:\n",
    "$$ P@K=\\frac{TP@K}{K}$$\n",
    "\n",
    "But which is the appropriate `K` value? To deal with this inconvenience, we use the average precision, which summarizes over different values as follows,\n",
    "\n",
    "$$AP@N = \\frac{1}{\\min(N,m)}\\sum_{K=1}^N P@K \\cdot rel(u,k)$$\n",
    "\n",
    "where `m` is the number of really relevant elements, and $rel(u,k)$ is a function that tells whether the `k`-th recommended element is really relevant to user `u` or not.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #3.-<br>\n",
    "<span style=\"color:black\">Why do we normalize the Average Precision with $\\min(m,N)$?</span></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In recommendation systems MAP computes the mean of the Average Precision (AP) over all your users. The AP is a measure that takes in a ranked list of your N recommendations and compares it to a list of the true set of \"correct\" or \"relevant\" recommendations for that user. AP rewards you for having a lot of \"correct\" (relevant) recommendations in your list, and rewards you for putting the most likely correct recommendations at the top (you are penalized more when incorrect guesses are higher up in the ranking). So order of \"hits\" and \"misses\" matters a lot in computing an AP score, but once you have front-loaded your best guesses you can never decrease your AP by tacking on more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Question #4.-<br>\n",
    "<span style=\"color:black\">Implement AP@N.</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4\n",
    "def APatN(l_pred, l_real, N):\n",
    "    '''Calculate Average Precision at N. Assumes that there is no repeated elements in l_pred, \n",
    "       and l_pred needs to be in descending ordering. '''\n",
    "    AP = 0.0\n",
    "    TP = 0.0\n",
    "\n",
    "    for i,item in enumerate(l_pred):\n",
    "        if item in l_real:\n",
    "            TP += 1\n",
    "            ### TODO: computate Precision@K and add it to AP\n",
    "\n",
    "    return AP / min(len(l_real), N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can test the Average Precision at N of the recommendations that we make to an user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u=7\n",
    "N=10\n",
    "l_pred = my_recsys.get_top_N_recommendations(user_id=u,N=N)\n",
    "\n",
    "userLikedMovies = tsData[ tsData['user_id'] == u ] \n",
    "l_real = list(userLikedMovies.movie_id[ userLikedMovies['rating'] > 3 ]) # we assume like if rating > 3\n",
    "\n",
    "print('AP@N (with N=',N,') for user',u,': %s' % APatN(l_pred, l_real, N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, so far, we only have considered the case of a single recommendation (for a single user). To average over multiple users, we use the Mean Average Precision:\n",
    "$$MAP@N=\\frac{1}{|U|}\\sum_{u=1}^{|U|}AP_u@N=\\frac{1}{|U|}\\sum_{u=1}^{|U|}\\frac{1}{\\min(N,m)}\\sum_{K=1}^{N}P_u@K\\cdot rel(u,k)$$\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "Question #5.-<br>\n",
    "<span style=\"color:black\">Implement MAP@N.</span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5\n",
    "def MAPatN(lists_pred, lists_real, N):\n",
    "    print(\"get_top_N_recommendations: not implemented yet\")\n",
    "\n",
    "\n",
    "def evaluate_topN(estimation_func, myTsData, metric=MAPatN, N=10):\n",
    "    '''Performance evaluation of Top-N-based recommendations.'''\n",
    "\n",
    "    dfPosScores = myTsData[ myTsData['rating'] > 3 ] # we assume like if rating > 3\n",
    "    lists_real = dfPosScores.groupby('user_id')['movie_id'].apply(list)\n",
    "    lists_real = [ lists_real.iloc[i] for i in range(len(lists_real))]\n",
    "    \n",
    "    # find the users\n",
    "    users_in_tspos = list(dfPosScores.user_id.unique())\n",
    "\n",
    "    # we do obtain the recommendations for all the users\n",
    "    lists_recommendations = [ estimation_func(u,N) for u in users_in_tspos ]\n",
    "\n",
    "    return metric(lists_recommendations, lists_real, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can test the CF RecSys when it provides Top-N recommendations (we keep a subsample of the test set; otherwise, this might take so long!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "# select a subset of users\n",
    "users = list(tsData['user_id'].unique())\n",
    "random.shuffle(users)\n",
    "users = users[:int(len(users)*0.1)]\n",
    "# select the data of that subsample of users\n",
    "tsSubData = tsData[tsData['user_id'].isin(users)]\n",
    "\n",
    "print('MAP@N (with N=',N,') for Collaborative Recommender: %s' % evaluate_topN(my_recsys.get_top_N_recommendations, \n",
    "                                                                               tsSubData,\n",
    "                                                                               N=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
