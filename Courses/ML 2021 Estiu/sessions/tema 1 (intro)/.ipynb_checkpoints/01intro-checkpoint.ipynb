{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNz7eHPASBC1"
   },
   "source": [
    "`Lab creado por Margarita Geleta para el curso Introducción a Machine Learning JEDI, edición 2021`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s31ilB5aSBC5"
   },
   "outputs": [],
   "source": [
    "! pip3 install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2oTLPLJ4SBC8"
   },
   "source": [
    "# [I] Introducción a Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waGgHukXSBC9"
   },
   "source": [
    "> Objetivo: **Predicción**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AA_RdGKLSBC-"
   },
   "source": [
    "El aprendizaje automático es un campo de las ciencias de computación que interseca estadística, probabilidad, optimización y algoritmia, cuyo objetivo es explorar métodos automáticos para inferir modelos a partir de datos.\n",
    "\n",
    "Es decir, que las máquinas (computadoras) *aprendan*. Un modelo capta patrones, cuando la máquina vuelve a ver los mismos patrones en los datos, los detecta. Esta detección es lo que aprende. Gracias a esto, podemos hacer predicciones.\n",
    "\n",
    "**Un sistema aprende si utiliza su anterior experiencia para mejorar el posterior rendimiento.**\n",
    "\n",
    "¿Cómo lo hacemos con máquinas?\n",
    "\n",
    "- La máquina analiza los datos (obtiene experiencia).\n",
    "- Construye un modelo que resume las regularidades (patrones) encontrados en el conjunto de datos analizados. El objetivo es contruir un modelo que **generalice** los datos.\n",
    "- Utilizar el modelo para hacer predicciones.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUUlW5ueSBC_"
   },
   "source": [
    "### Machine Learning VS Programación \"tradicional\"\n",
    "\n",
    "<div style=\"display:flex; justify-content: center;\">\n",
    "    <img src=\"data/intro.png\" alt=\"drawing\" style=\"height:400px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ByReX9qJSBDA"
   },
   "outputs": [],
   "source": [
    "# Tradicional #\n",
    "def fiebre(T):\n",
    "    return 1 if T >= 37 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlW9ts72SBDA"
   },
   "outputs": [],
   "source": [
    "fiebre(36.2), fiebre(38.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S1rEwFyCSBDC"
   },
   "outputs": [],
   "source": [
    "# Machine Learning #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "X = np.array([36.4, 37.2, 36.7]).reshape(-1, 1)\n",
    "Y = np.array([0, 0, 1]).reshape(-1, 1)\n",
    "\n",
    "fiebre = tree.DecisionTreeClassifier()\n",
    "fiebre.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drPuYL7jSBDE"
   },
   "outputs": [],
   "source": [
    "fiebre.predict(np.array([36.2, 38.8]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a7N0-ktSBDF"
   },
   "outputs": [],
   "source": [
    "tree.plot_tree(fiebre, impurity = False, \n",
    "               class_names = ['No','Si'],\n",
    "              feature_names = ['Temperatura']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-h9YhW2SBDH"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwjBKMamSBDI"
   },
   "source": [
    "### Subcampos de Machine Learning\n",
    "\n",
    "<div style=\"display:flex; justify-content: center;\">\n",
    "    <img src=\"data/intro2.png\" alt=\"drawing\" style=\"height:400px;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95sj_Ll6SBDJ"
   },
   "source": [
    "Machine Learning tiene varios subcampos. La taxonomía es la siguiente:\n",
    "\n",
    "- **Supervised learning** (aprendizaje supervisado): el modelo $f$ crea una correspondencia con los datos de entrada $X$ y sus respectivas etiquetas $Y$, es decir $f(x)=y$. Hay dos tipos:\n",
    " - *Clasificación*: el objetivo es predecir una clase (o categoria) de cada ejemplo $x_i$. Hay variaciones: clasificación binaria / multiclase, clasificación probabilísitica, etc. La variable $Y$ es categórica.\n",
    " - *Regresión*: el objetivo es predecir un valor numérico de cada ejemplo $x_i$. $Y$ puede ser entera o contínua.\n",
    "- **Unsupervised learning** (aprendizaje no supervisado): no disponemos de $Y$. El modelo $f$ debe reconocer los patrones de los datos para poder etiquetar las entradas $X$.\n",
    " - *Clustering*: descubrir grupos en los datos. Estos grupos se llaman *clusters*.\n",
    " - *Reducción de dimensionalidad*: reducir la dimensionalidad de los datos. Lo veremos mañana.\n",
    " \n",
    "Hay otros más, como el *aprendizaje por refuerzo*, *aprendizaje semi-supervisado* ... pero en este curso nos centraremos en los dos subcampos citados.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sab3gjHMSBDJ"
   },
   "source": [
    "> Ejemplos: www.kaggle.com "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIGz4Q4eSBDJ"
   },
   "source": [
    "**Kaggle** (de *Google*) es una plataforma que organiza competiciones de ML y DL. En *datasets* encontramos un extenso repositorio con diferentes datasets de todo tipo.\n",
    "\n",
    "- Muy famoso: **Titanic: Machine Learning from Disaster**, predecir la supervivencia en el Titanic a partir de muchas variables como el nombre, la edad, la clase socio-económica, etc.\n",
    "- Identificar quién hará una transacción bancaria (https://www.kaggle.com/c/santander-customer-transaction-prediction) 65.000\\$\n",
    "- Predecir la capacidad de devolver un préstamo del banco (https://www.kaggle.com/c/home-credit-default-risk) 70.000\\$\n",
    "- Identificar comentarios tóxicos (https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge) 35.000\\$\n",
    "- Más en https://www.kaggle.com/competitions ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bCsn1BsmSBDK"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UcH4TW13SBDK"
   },
   "source": [
    "### Overfitting & Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "syO886eYSBDK",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def gen_data(N = 5000):\n",
    "    x = 2.0 * (np.random.rand(N) - 0.5) \n",
    "    f = lambda x: np.exp(-x**2) * (-x) * 5 + x / 3\n",
    "    y = f(x) + np.random.randn(len(x)) * 0.5\n",
    "    return x, y, f\n",
    "\n",
    "x, y, f = gen_data(N = 1000)\n",
    "xp = np.linspace(-1, 1, 10000) \n",
    "\n",
    "fig, ax = plt.subplots(4, 1, figsize = (16,16))\n",
    "for n in range(4):\n",
    "    for k in range(1):\n",
    "\n",
    "        order = 10 * n + 10 * k + 1\n",
    "        z = np.polyfit(x, y, order)\n",
    "        p = np.poly1d(z)\n",
    "\n",
    "        ax[n].scatter(x, y, label = \"Datos reales\", s = 10)\n",
    "        ax[n].plot(xp, f(xp), label = \"Función real\", color = 'black', linewidth = 5)\n",
    "        ax[n].plot(xp, p(xp), label = \"Polinomio de orden = {}\".format(order), color = 'C1', linewidth = 3)\n",
    "        ax[n].legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZhGWd9wSBDL"
   },
   "source": [
    "¿Qué modelo $f$ es mejor? Basándonos solo en los datos de Training no podemos decidir qué modelo es mejor. Necesitamos añadir \"algo\" la complejidad de nuestro modelo. Un modelo demasiado complejo tiende a aprender demasiado los patrones propios del conjunto de Training, con lo cual no generaliza.\n",
    "\n",
    "El objetivo es conservar la señal (el patrón) y negligir el ruido (error). A esto se le llama **generalizar**.\n",
    "\n",
    "- El error es la aleatoriedad presente en la naturaleza y en los datos.\n",
    "- El patrón es la regularidad presente en la naturaleza y en los datos.\n",
    "\n",
    "El overfitting pasa cuando el modelo $f$ empieza a aprender el error (cuando empieza a considerarlo como patrón). El modelo $f$ es demasiado complejo y tiene mucha variancia (variance).\n",
    "\n",
    "El underfitting pasa cuando el modelo $f$ no aprende lo bastante (ni siquiera detecta el patrón de la señal). El modelo $f$ es demasiado simple y tiene mucho cesgo (bias).\n",
    "\n",
    "Debemos encontrar un modelo que tenga un balance entre el cesgo y la variancia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dH8kuGlvSBDL"
   },
   "source": [
    "### (1) ¿Cómo detectar overfitting?\n",
    "\n",
    "- Si el modelo es mucho mejor que en training que en test (el error de training << error de test), seguramente estamos haciendo overfitting.\n",
    "- Si dos modelos aproximadamente tienen el mismo rendimiento, opta por el más simple.\n",
    "\n",
    "### (2) ¿Cómo detectar underfitting?\n",
    "\n",
    "- Si es malo en todo. Así de simple.\n",
    "\n",
    "### (3) ¿Qué podemos hacer parar evitar overfitting?\n",
    "\n",
    "- Dividir los datos en conjuntos de training y test (training, validación y test).\n",
    "\n",
    "- Realizar Cross-Validation (CV):\n",
    "\n",
    "Generar pequeños subconjuntos de train y test dentro del training set. $k$-fold CV parte el conjunto de training en $k$ subconjuntos (llamados \"folds\"). Entrenar el algoritmo con $m$ combinaciones utilizando $k-1$ subconjuntos como training y $1$ como test (llamado \"holdout fold\").\n",
    "\n",
    "- Añadir más datos al conjunto de training: \n",
    "\n",
    "Esto no es siempre posible (ej. datos médicos). Más datos normalmente ayudan a detectar mejor la señal, a no ser que añadamos datos muy ruidosos y fuera de contexto.\n",
    "\n",
    "- Trabajar con las features:\n",
    "\n",
    "Escoger bien las variables (feature selection) es muy importante. Meter todas las variables en el modelo quizás no sea la mejor opción (algunas variables no aportan información, son irrelevantes o redundantes). También es posible crear nuevas variables que pueden capturar más información (feature extraction), por ej. PCA.\n",
    "\n",
    "- Añadir regularización: \n",
    "\n",
    "La regularización es una penalización sobre la complejidad. Esta técnica fuerza que los modelos sean más simples. De esta manera penalizamos ambos: el error de training (error de ajuste a los datos) y la complejidad.\n",
    "\n",
    "- Ensembling:\n",
    "\n",
    "Entrenar varios modelos independientes y combinar sus predicciones. Lo veremos más adelante en el curso.\n",
    "\n",
    "A continuación, ejemplo de https://scikit-learn.org/stable/auto_examples/model_selection/plot_underfitting_overfitting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bt69o6yuSBDM"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "def true_fun(X): return np.sin(1.5 * np.pi * X)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "n_samples = 30\n",
    "N = 100\n",
    "degrees = [1, 2, 4, 8, 10, 15]\n",
    "\n",
    "X_train = np.sort(np.random.rand(n_samples))\n",
    "Y_train = true_fun(X_train) + np.random.randn(n_samples) * 0.1\n",
    "\n",
    "X_test = np.sort(np.random.rand(N))\n",
    "Y_test = true_fun(X_test) + np.random.randn(N) * 0.1\n",
    "\n",
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "for i in range(len(degrees)):\n",
    "    ax = plt.subplot(2, len(degrees) // 2, i + 1)\n",
    "    plt.setp(ax, xticks = (), yticks = ())\n",
    "\n",
    "    polynomial_features = PolynomialFeatures(degree = degrees[i],\n",
    "                                             include_bias = False)\n",
    "    linear_regression = LinearRegression()\n",
    "    pipeline = Pipeline([(\"polynomial_features\", polynomial_features),\n",
    "                         (\"linear_regression\", linear_regression)])\n",
    "    pipeline.fit(X_train[:, np.newaxis], Y_train)\n",
    "\n",
    "    # Evaluate the models using crossvalidation\n",
    "    scores = cross_val_score(pipeline, X_train[:, np.newaxis], Y_train,\n",
    "                             scoring = \"neg_mean_squared_error\", cv = 10)\n",
    "\n",
    "    X_test = np.linspace(0, 1, 100)\n",
    "    plt.scatter(X_test, Y_test, s = 20, label = \"Test samples\", color = \"pink\")\n",
    "    plt.scatter(X_train, Y_train, edgecolor = 'b', s = 20, label = \"Train samples\")\n",
    "    plt.plot(X_test, true_fun(X_test), label = \"True function\", color = 'red')\n",
    "    plt.plot(X_test, pipeline.predict(X_test[:, np.newaxis]), label = \"Model\", color = 'blue')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.xlim((0, 1))\n",
    "    plt.ylim((-2, 2))\n",
    "    plt.legend(loc = \"best\")\n",
    "    plt.title(\"Degree {}\\nMSE = {:.5}(+/- {:.2})\".format(\n",
    "        degrees[i], -scores.mean(), scores.std()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "moIIfmXHSBDN"
   },
   "source": [
    "---\n",
    "\n",
    "### Métricas de evaluación\n",
    "\n",
    "No existe una única métrica de evaluación. Las métricas son esenciales para evaluar un modelo y dependen del tipo de modelo (modelo de regresión, clasificación, clustering ...). Es crucial escoger una métrica de evaluación correcta. \n",
    "\n",
    "IMPORTANTE: cuando ajustamos un modelo, minimizamos una función de coste (de error) con la que entrenamos un modelo. Las métricas con formulas de evaluación SOLO (por eso, no necesariamente deben ser diferenciables) aunque una fórmula de métrica podría usarse como una función de coste. \n",
    "\n",
    "Veremos a fondo las funciones de coste en el siguiente notebook.\n",
    "\n",
    "Veamos las métricas ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLqSqwyXSBDN"
   },
   "source": [
    "#### Métricas de Regresión\n",
    "\n",
    "- MSE (Mean Squared Error): el error cuadrático medio es la métrica más famosa y en muchos casos también se utiliza como función de coste en modelos de regresión. MSE encuentra el error cuadrático medio entre los valores reales y los predecidos:\n",
    "$$\n",
    "MSE = \\frac{1}{N}\\sum_{i=1}^N (y_i - f(x_i))^2\n",
    "$$\n",
    "\n",
    "- MAE (Mean Absolute Error): MAE encuentra el error absoluto medio entre los valores reales y los predecidos. Es más robusto que MSE respecto los outliers, ya que MSE, al tener el cuadrado, llama mucho la atención a los outliers.\n",
    "$$\n",
    "MSE = \\frac{1}{N}\\sum_{i=1}^N |y_i - f(x_i)|\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Alk3zQnSBDO"
   },
   "source": [
    "#### Métricas de Clasificación\n",
    "\n",
    "Podemos calcularlas a partir de la **matriz de confusión**. Supongamos clasificación binária. Creamos una matriz 2x2 (clase positiva, clase negativa) x (pred. positiva , pred. negativa). Hay 4 opciones: TP, TN, FP, FN. \n",
    "\n",
    "<div style=\"display:flex; justify-content: center;\">\n",
    "    <img src=\"data/intro3.png\" alt=\"drawing\" style=\"height:200px;\"/>\n",
    "</div>\n",
    "\n",
    "- Accuracy: la métrica más simple, correcto / total.\n",
    "$$ Accuracy = \\frac{TP + TN}{TP + TN + FP + FN}$$\n",
    "\n",
    "- Precisión: hay muchos casos cuando accuracy no es la mejor opción para evaluar (puede ser muy alta, pero el clasificador puede ser horrible). Uno de estos casos es cuando tenemos clases no balanceadas (una clase más frecuente que otras). Un clasificador con alta precisión es muy conservador, si no está seguro del todo no clasificará como positivo. Podemos tener más falsos negativos. **Un clasificador con alta precisión se centra en buscar SOLO los casos relevantes (positivos).**\n",
    "\n",
    "$$ Precision = \\frac{TP}{TP+FP}$$\n",
    "\n",
    "- Recall: es el opuesto. Un clasificador con recall alta clasifica más en positivo y podemos tener más falsos positivos. **Un clasificador con recall alta se centra en buscar TODOS los casos relevantes (positivos).**\n",
    "\n",
    "$$Recall = \\frac{TP}{TP+FN}$$\n",
    "\n",
    "- F1-Score: hay aplicaciones donde la precisión es más importante que recall, y viceversa, pero a veces nos es indiferente o ambas son importantes. F1-Score es una métrica que combina las dos métricas, haciendo una media harmónica entre los dos valores:\n",
    "\n",
    "$$F1Score = \\frac{2TP}{2TP+FN + FP}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0EoK88OSBDO"
   },
   "source": [
    "Las métricas de clustering ya las veremos más adelante."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01intro.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
